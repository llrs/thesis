# Materials and methods

This chapter explains the methods used to collect and analyze data from the multiple cohorts analyzed.
The actual code used can be found on the links of the [appendix](#software "Link to the software appendix").

Some sections of this chapter has been adapted from "Multi-Omic Modelling of Inflammatory Bowel Disease with Regularized Canonical Correlation Analysis" [@revilla2021] or other publications of the research group.

Samples of the different cohorts collected on the Hospital Clínic were collected similarly, differences are described below together with a brief description of the main characteristics of the different datasets.
The processing protocol followed for those dataset that were not generated at Hosptial Clínic can be found on their respective reference and briefly summarized here.

## Datasets

### Puget's dataset {#methods-puget}

The glioma dataset is the data provided as an example by the authors of RGCCA from a previous pulication [@puget2012].
The data came from diffuse intrinsic pontine glioma patients that included the host transcriptome analyzed with Agilent 44K Whole Human Genome Array G4410B and G4112F, patients copy number variation was processed with the ADM-2 algorithm, and data from comparative genomic hybridization (CGH) analyzed using [Mutation Surveyor software](https://www.softgenetics.com/mutationSurveyor.php "Website of the software").
In addition, this dataset contained information on age, localization of the tumor, sex and a numerical grading of the severity of the tumor [@puget2012].

| Characteristic            | Puget's  |
|---------------------------|----------|
| Samples                   | 53       |
| Sex (female/male)         | 28/25    |
| Location (cort/dipg/midl) | 20/22/11 |

: Table about Puget's dataset

### Häsler's dataset {#methods-hasler}

An IBD-related dataset was obtained by Prof. Dr. Rosentiel and Prof. Dr. Robert Häsler.
It included samples from the terminal ileum and sigma from CD, UC, infectious disease-controls and healthy controls [@häsler2017].
The provided data included location, gender, location, age, and the status (inflamed or non-inflamed) of the region from which the biopsy was taken.

| Characteristic                 | Häsler's |
|--------------------------------|----------|
| Samples (non-disease/diseased) | 33/26    |
| Sex (female/male)              | 42/17    |
| Location (ileum/colon)         | 30/29    |

: Table of Häsler's dataset

### Morgan's dataset {#methods-morgan}

A previously published dataset from a pouchitis study was analyzed [@morgan2015b].
The dataset has a total of 255 samples from 203 patients, containing data for both host transcriptome and intestinal microbiome.
This dataset included anonymous identifiers for the patients, whether the sample was from the pre-pouch ileum (PPI) or from the pouch, the sex, the outcome of the procedure and an inflammatory severity score ISCORE.
The pouch ileum might be inflamed or not.

| Characteristic                | Morgan's |
|-------------------------------|----------|
| Samples                       | 255      |
| Sex individuals (female/male) | 101/102  |
| Location (Pouch/PPI)          | 59/196   |

: Table of Morgan's dataset

### HSCT dataset {#methods-hsct}

<!--# COPIED!!! from article https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0246367#sec005 -->

Samples from the HSCT dataset used in this thesis were from a cohort of patients with severe refractory CD undergoing hematopoietic stem cell transplant.
Patients were treated in the Department of Gastroenterology (Hospital Clínic de Barcelona --Spain--).
The protocol was approved by the Catalan Transplantation Organization and by the Institutional Ethics Committee of the Hospital Clinic de Barcelona (Study Number HCB/2012/7244).
All patients provided written consent following extensive counselling about being included on the study and using their data on publications.

Colonic and ileal biopsies were obtained at several time points during ileo-colonoscopy, at inclusion and every six or twelve months after HSCT until 4 years after the start of the treatment.
Samples were obtained whenever possible from both uninvolved and involved areas.
In addition, biopsies were taken from the ileum and colon regions of 19 non-IBD controls consisting of individuals with no history of IBD and who presented no significant pathological findings following endoscopic examination for colon cancer surveillance (Hospital Univesitari Mútua de Terrassa--Spain--).
The protocol was approved by the Institutional Ethics Committee of the Hospital Univesitari Mútua de Terrassa (Study Number NA1651).

At least one biopsy was collected and fresh-frozen at -80°C for microbial DNA extraction.
The remaining biopsies were placed in RNAlater RNA Stabilization Reagent (Qiagen, Hilde, Germany) and stored at -80°C until total RNA extraction.

| Characteristic                          | HSCT        |
|-----------------------------------------|-------------|
| Sex (female/male)                       | 22/15       |
| Age at diagnostic (\<17/\<40/>40 years) | 7/11/0      |
| Years of disease: mean (min-max)        | 14 (8-28)   |
| Age: mean (min-max)                     | 44 (23-70)  |
| Samples (non-disease/CD)                | 51/107      |
| Location (ileum/colon/unknown)          | 48/108/2    |
| SES-CD local: mean (min-max)            | 2.15 (0-12) |
| CDAI: mean (min-max)                    | 120 (0-450  |

: Table of HSCT dataset.

### BARCELONA dataset {#methods-barcelona}

<!--# Adapted from the ethical committee submission-->

All patients with an established diagnosis of inflammatory bowel disease, including Crohn's disease, ulcerative colitis, IBD unclassified, indeterminate colitis, or pouchitis, starting treatment with a biologic agent were monitored following the schedule of clinical visits, laboratory tests, imaging procedures and biologic sampling at the beginning of their treatment with anti-TNF therapy and after 14 weeks and 46 weeks a biopsy from an ileocolonoscopy.
The protocol was approved by the Institutional Ethics Committee of the Hospital Clinic de Barcelona (Study Number HCB/2012/7845 and HCB/2012/7956).

Patients that were referred to the Hospital Clínic de Barcelona IBD unit, who had already started treatment with a biologic agent in another center, were also included adapting to the corresponding time-schedule of their treatment.
In all patients, starting anti-TNF treatment will be decided before the protocol entry decision according to medical clinical practice.

Anonymized identification of the patients, disease, sex age at diagnostic, age at the moment of the sample taking, time since the start of the treatment and sample segment was collected.

| Characteristic                          | BARCELONA  |
|-----------------------------------------|------------|
| Individuals                             | 62         |
| Status (CD/UC/Controls)                 | 33/21/8    |
| Sex (female/male)                       | 29/33      |
| Age at diagnostic (\<17/\<40/>40 years) | 2/44/8     |
| Years of disease: mean (min-max)        | 7.6 (0-32) |
| Age: mean (min-max)                     | 41 (18-68) |
| Time (0/14/46 weeks)                    | 41/40/32   |
| Sample segment (ileum/colon)            | 39/87      |

: Table of samples included from the BARCELONA dataset.

### Howell's dataset {#methods-howell}

This dataset was downloaded after the publication of an article "DNA Methylation and Transcription Patterns in Intestinal Epithelial Cells From Pediatric Patients With Inflammatory Bowel Diseases Differentiate Disease Subtypes and Associate With Outcome" [@howell2018].

From their dataset I used data from 77 samples that had both RNAseq and 16S data collected.
There are 10 non-IBD samples, 11 with Crohn's disease and 11 with ulcerative colitis.
Data has the following characteristics: disease, age at diagnostic, age at the moment of the study, sex, segment, and clinical history which have the following characteristics:

| Characteristic                                  | Howell's  |
|-------------------------------------------------|-----------|
| Disease (CD/UC/controls)                        | 10/11/11  |
| Age at diagnostic (\<17/\<40/>40 years)         | 32/0/0    |
| Age: mean (min-max)                             | 12 (6-15) |
| Sex (female/male)                               | 10/22     |
| Segment (ileum/colon)                           | 31/46     |
| Clinical history (inflammation/no inflammation) | 24/53     |

: Table of samples included from Howell's dataset.

### Hernández' dataset {#methods-hernandez}

This dataset was obtained after a collaboration "Integrative analysis of colonic biopsies from inflammatory bowel disease patients identifies an interaction between microbial bile-acid inducible gene abundance and human Angiopoietin-like 4 gene expression" [@hernández-rocha2021a].

<!--# TODO table of patients and samples -->

| Characteristic                          | Hernández' |
|-----------------------------------------|------------|
| Disease (CD/UC/controls)                |            |
| Age at diagnostic (\<17/\<40/>40 years) |            |
| Age: mean (min-max)                     |            |
| Sex (female/male)                       |            |
| Segment (ileum/colon)                   |            |
|                                         |            |
|                                         |            |

: Table of samples included from Hernández's dataset.

## Processing samples

### Transcriptome sequencing

Total RNA from mucosal samples (HSCT cohort) was isolated using the RNAeasy kit (Qiagen, Hilde, Germany).
RNA sequencing libraries were prepared for paired-end sequencing using HighSeq-4000 platform.
Later, those samples with good enough quality as recommended by [FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/ "FastQC website") afterwards [cutadapt](https://github.com/marcelm/cutadapt "cutadapt repository") (version 1.7.1) [@martin2011] was used for quality filtering and the libraries were mapped against the human reference genome using the [STAR aligner](https://github.com/alexdobin/STAR "STAR repository") (2.5.2a) with Ensembl annotation ([release 26 of GENCODE](https://www.gencodegenes.org/human/release_26.html "GENCODE release 26"), GRCh38.p10 or superior) [@dobin2013].

<details>

<summary>

Code used with STAR

</summary>

    STAR \
        --outSAMtype BAM SortedByCoordinate \
        --outFilterIntronMotifs RemoveNoncanonical \
        --outSAMattributes All \
        --outReadsUnmapped Fastx \
        --outSAMstrandField intronMotif \
        --outFilterScoreMinOverLread 0.5 \
        --outFilterMatchNminOverLread 0.5 \
        --outFilterType BySJout \
        --alignSJoverhangMin 8 \
        --alignSJDBoverhangMin 1 \
        --outFilterMismatchNmax 999 \
        --outFilterMismatchNoverLmax 0.04 \
        --genomeDir "$genome/STAR" \
        --limitBAMsortRAM 10000000000 \
        --runMode alignReads \
        --genomeLoad NoSharedMemory \
        --quantMode TranscriptomeSAM \
        --outFileNamePrefix $output \
        --runThreadN "$threads" \
        --readFilesCommand zcat \
        --readFilesIn "$file1" "$file2"

</details>

Read counts per gene were obtained with [RSEM](https://github.com/deweylab/RSEM "RSEM repository") (version 1.2.31) [@li2011] as previously described [@corralizaDifferencesPeripheralTissue].

<details>

<summary>

Code used with RSEM

</summary>

    rsem-calculate-expression \
        --quiet \
        --paired-end \
        -p "$threads"  \
        --estimate-rspd \
        --append-names \
        --no-bam-output \
        --bam "$rseminp" "$genome/RSEM/RSEM" "$rsem"

</details>

### Microbial DNA sequencing

Biopsies from the HSCT CD cohort were resuspended in 180 μl TET (TrisHCl 0.02M, EDTA 0.002M, Triton 1X) buffer and 20mg/ml lysozyme (Carl Roth, Quimivita, S.A.). Samples were incubated for 1h at 37°C and vortexed with 25 μl Proteinase K before incubating at 56°C for 3h.
Buffer B3 (NucleoSpin Tissue Kit--Macherey-Nagel) was added followed by a heat treatment for 10 min at 70°C.
After adding 100% ethanol, samples were centrifuged at 11000 x g for 1 min.
Two washing steps were performed before eluting DNA.
Concentrations and purity were checked using NanoDrop One (Thermo Fisher Scientific).
Samples were immediately used or placed at -20°C for long-term storage.

#### DNA sequencing

Library preparation and sequencing were performed at the Technische Universität München.
Briefly, volumes of 600μL DNA stabilization solution (STRATEC biomedical) and 400μL Phenol:choloform:isoamyl alcohol (25:24:1, Sigma-Aldrich) were added to the aliquots.
Microbial cells were disrupted by mechanical lysis using FastPrep-24.
Heat treatment and centrifugation were conducted after adding a cooling adaptor.
Supernatants were treated with RNase to eliminate RNA.
Total DNA was purified using gDNA columns as described in detail previously [@berry2011].
Briefly, the V3-V4 regions of 16S rRNA gene were amplified (15x15 cycles) following a previously described two-step protocol [@klindworth2013] using forward and reverse primers 341F-ovh/785R-ovh [@edgar2013a].
Purification of amplicons was performed by using the AMPure XP system (Beckmann).
Next, sequencing was performed with pooled samples in paired-end modus (PE275) using an MiSeq system (Illumina, Inc.) according to the manufacturer's instructions and 25% (v/v) PhiX standard library.

<!--# Macrogen: 341f/785r not used/contaminated --->

On the BARCELONA dataset the data was processed using 16S-V3V4 primers pair 341f/806r on a MiSeq Nano sequencing bcl2fastq (v1.8.4).
The sequence of the primers used was:

341f: 5'-CCTACGGGAGGCAGCAG-3'\
806r: 5'-GGACTACHVHHHTWTCTAAT-3'

#### Microbial profiling

For the HSCT dataset the processing of raw-reads was performed by using the [IMNGS](https://www.imngs.org/ "IMNGS website") (version 1.0 Build 2007) [@lagkouvardos2016] pipeline based on the [UPARSE](https://www.drive5.com/uparse/ "UPARSE website") approach [@edgar2013a].
Sequences were demultiplexed, trimmed to the first base with a quality score \<3 and then paired.
Sequences with less than 300 and more than 600 nucleotides and paired reads with an expected error \>3 were excluded from the analysis.
The 5 nucleotides from each end of the remaining reads were trimmed to avoid GC bias and non-random base composition.
Operational taxonomic units (OTUs) were clustered at 97% sequence similarity.
Taxonomy assignment was performed at 80% confidence level using the RDP classifier and the SILVA ribosomal RNA gene database project.
Later the data was normalized using the same method as for RNA-seq described above.
The microbiome was visually inspected for batch effects in PCA; none were found.
The resulting OTUs table was normalized using edgeR (Version 3.28 or later) [@mccarthy2012].

For all the other datasets [dada2](https://bioconductor.org/packages/dada2) [@callahan2016] was used to analyze microbiome data.
It creates amplicon sequencing variants from the 16S sequencing data, without merging similar sequences at any threshold.
It is an alternative to OTUs which allows to be able to compare results between studies because it doesn't summarize together any sequence and provides more resolution to differences on the fragment amplified.

## Statistics

Differential expression analysis was performed with the following the limma-trend method [@ritchie2015; @law2014] and edgeR [@mccarthy2012] (Bioconductor version 3.10 or superior) packages, normalized using the trimmed mean of M-values and log-2 transformed into counts per millions following the workflow described on [@law2018] using voom which in addition performs a count normalization.
The samples were adjusted for inter-patient differences specifying block argument for patient variable.

To correct for multiple testing, the false discovery rate was estimated using the method of Benjamini and Hochberg [@yoavbenjamini].
A gene was considered differentially expressed when it was significant at 5% FDR special attention was given to those genes that showed a fold-change higher than \|1.5\|.

Besides differential expression tests and correction for multiple testing, several different methods were used on this thesis which will be described below.
Functional enrichment related tests/methods stand out from the other methods used.

### Functional enrichment

Functional enrichment methods are those methods that aim to provide with more information about the variables besides their numerical value measured.
They can be very different in nature but they all use the numeric values of the variables and other information, being it from the same experiment data collection or from external data sources.
Most of them are based on an over representation analysis (ORA), where a group of elements is tested whether they are present on other group.
This can be done with [clusterProfiler](https://bioconductor.org/packages/clusterProfiler) which tests genes enrichment for functionality based on information on pathway databases [@wu2021].
It checks the enrichment of features of a given group on the (background) list provided.

$$
\begin{cases}
H_0 & : & P_{subset} \leq  P_{overall} \\
H_1 & : & P_{subset} > P_{overall}
\end{cases}
$$

The test used is usually the fisher test, the hypergeometric test, the proportion test.
I describe the hypergeometric test and the wilcoxon test below.

#### Hypergeometric test

The hypergeometric distribution describes the probability of $k$ successes (when the object drawn has a specified feature) in $n$ draws[^methods-1], from a finite population of size $N$ that contains exactly $K$ objects with that feature, wherein each draw is either a success or a failure.

[^methods-1]: without replacement

Applied on this context $N$ is the number of genes being used and $n$ the number of genes on a pathway.
So it can be used to compare the genes found on it ($k$) compared to the expected $K$ numbers of the distribution using the following equation:

$$
p_X(k) = \Pr(X = k) 
= \frac{\binom{K}{k} \binom{N - K}{n-k}}{\binom{N}{n}}
$$

#### Proportion test

The overrepresentation of a given group of elements can be also tested with the proportion test, which is sometimes also used on clusterProfiler.
The proportion test uses the $\chi^2$ distribution to test if the observed frequency ($O_i$) is close to the expected frequency ($E_i$):

$$
\chi^2 = \sum_{i =1}^n \dfrac{(O_i - E_i)^2}{E_i}\simeq\chi_{n-p}^2
$$

As this is usually done on a 2x2 contingency table it is equivalent to the Z-test of proportion.
Sometimes, the expected frequency is so low that a correction must be done to the estimation:

$$
\chi_{Yates}^2=\sum_{i =1}^n \dfrac{(|O_i - E_i|-0.5)^2}{E_i}
$$

This increases the $p$-value as it raises the Chi-square statistic.

#### Gene Set Enrichment Analysis

There are other methods that to test if some variables shows an unexpected importance according to a statistic like fold change or value gene set enrichment analysis was developed [@subramanian2005] .
Gene set enrichment analysis (GSEA) is a computational method originally developed to determine whether a priori defined set of genes shows statistically significant and concordant differences between two biological states.
These methods check if a group of variables present in an ordered list is present in some skewed distribution and compare it against a random group of similar size.

This method consist on first calculating the rank of genes:$rank(g_j)=r_j$ where each $g$ is a gene.
Then later calculate the following functions:

$$
P_{hit}(S, i)=\sum_{g_j \in S, j \leq i}\dfrac{|r_j|^p}{N_R}\text{, where } N_R = \sum_{g_j \in S}|r_j|^p
$$

$$
P_{miss}(S, i) = \sum_{g_j \not \in S, j \leq i}\dfrac{1}{N - N_H}
$$

With these values the enrichment score (ES) defined as: $ES=max(|P_{hit}(S, i)-P_{miss}(S, i)|)$ is calculated from the walk.
A high number of permutations are required for an accurate score of the enrichment score.
However, when more than one pathway ($S$) is evaluated in order to compare between the enrichment scores, they must be normalized by dividing it by the mean of all the ES.
When power $p$ is 0 it is equivalent to the standard Kolmogorov--Smirnov statistic, though it is usually set to 1.

For testing gene set enrichment analysis I used [fgsea](https://bioconductor.org/packages/fgsea) [@korotkevich2021] implementation for its speed and integration with other methods used on this thesis.
Pathways of genes from the REACTOME database were tested on the weight of different models or on the comparisons performed [@fabregat2016].

#### GSVA

To estimate the expression of the pathways and compare their expression levels between conditions gene set variation analysis as implemented on [GSVA](https://bioconductor.org/packages/GSVA) was used [@hänzelmann2013].
It is a method that summarize the variables' numerical value changing the space of $variable\text{ x }sample$ to $group\text{ x }sample$ .
This enables other methods to use this new space instead of the original variables.
GSVA was used (again from the REACTOME database) and try to find the relationships between the pathways and the microbiome at different taxonomic levels.

This is done via an estimation and a comparison with a discrete Poisson kernel: $i$ indicates the gene till $k$ and samples are indicated by $j$ till $n$.

$$
z_{ij}=\hat{F_r}(x_{ij}) = \frac{1}{n}\sum_{k=1}^n\sum_{y=0}^{x_{ij}}\dfrac{e^{-(x_{ik}+r)}(x_{ik} + r)^y }{y!}
$$

where $r = 0.5$ is used in order to set the mode of the Poisson kernel at each $x_{ik}$, that is, similar to a gene expression for a given sample.

Later this is converted to ranks $z_{(i)j}$ for each sample and normalized: $r_{ij}=|\frac{p}{2}-z_{(i)j}|$ to make the distribution of ranks symmetric around zero to later compare with a normal distribution using a Kolmogorov-Smirnov-like random walk statistic:

$$
v_{jk}(l)=\dfrac{\sum_{i=1}^l|r_{ij}|^{\tau}I(g_{(i)}\in \gamma_k)}{\sum_{i=1}^p|r_{ij}|^{\tau}I(g_{(i)}\in \gamma_k)}-\dfrac{\sum_{i=1}^lI(g_{(i)}\not \in\gamma_k)}{p-|\gamma_k|}
$$

Here tau $\tau$ describes the weight of the tail in the random walk (default is set to 1).
$\gamma_k$ is the k-th gene set and $I(g_{(i)}\in \gamma_k)$ is the indicator function whether the gene ranked i-th belongs to the gene set $\gamma_k$ .
$|\gamma_k|$ indicates the ordination of the gene set, the number of genes of the gene set and $p$ the number of genes in the data set.

This difference is later converted to enrichment score for each gene set for each sample similar to GSEA, either a difference of hits and misses or the maximum deviation from zero of the random walk (which is used as it allows to detect gene sets that have genes with different expression patterns).

### Other methods used

#### PERMANOVA

The PERMANOVA method [@anderson2001; @warton2012], provided by the [vegan](https://cran.r-project.org/package=vegan) package on the `adonis` function, was used to test if microbiome data variance is due to other variables when using distances metrics.
It uses the residual sum of squares such as:

$$
SS_W = \frac{1}{n} \sum_{i=1}^{N-1}\sum_{j=i+1}^N d_{ij}^2\epsilon{ij} 
$$

Which when using euclidian distances ($d$) it is equivalent to MANOVA.
Here $\epsilon_{ij}$ takes the value of 1 if the observation $i$ and the observation $j$ are in the same group, otherwise it takes the value of zero.
This can be later used to test which variance is bigger, inter-groups or intra-groups by using the following formula:

$$
F = \dfrac{SS_A/(\alpha -1)}{SS_W/(N-\alpha)}
$$

Where $SS_A$ is the among group sum of squares, representing the intra-group variance.
$N$ is the number of samples and $\alpha$ the number of different groups.

This allows to test if the variables are related to the variance of the data as it can be compared with the $F$ statistic after a high number of permutations.
This is particularly important on the microbiome data, which is highly variable.
It was used to detect which variables were important to include in the models of the disease.

Variables were tested together in an interaction model and also each one individually alone with the blocks of data.

#### globaltest

I tested which variables, (sex, age, location, time since diagnostic, treatment) are important on the datasets with [globaltest](https://bioconductor.org/packages/globaltest).
It is a package with methods for testing complex hypothesis and help decide if the variables were influencing [@goeman2006].
It provides a general test statistic to test a hypothesis against a high dimensional dataset.

$$
S = \sum_{i=1}^p x_i^{'} x_i g(t_i^2)
$$

The global test performs a test statistic on the tranformed t-test, where if $p$, the number of variables, is large the test is more powerful on average over all possible sparse alternatives of general functions $g$.

It was performed with variables individually and also with interactions between the different variables.

#### Diversity indices

Microbiome diversity was measured using vegan and [phyloseq](https://bioconductor.org/packages/phyloseq) methods [@oksanen2020].
$\alpha$-diversity is a measure of how much a given microbiome at a taxonomic level is present on a sample.
Several measures exists, on the thesis I used the effective Simpson or Shannon diversity index to compare diversity between samples and conditions.
$\beta$-diversity was calculated using the phyloseq package for exploratory analysis.

#### WGCNA

We wanted to see if using some co-expression measure between the microbiome and the RNAseq would help identify relationships.
We used weighted gene co-expression network analysis as implemented on [WGCNA](https://cran.r-project.org/package=WGCNA) [@langfelder2008] and also correlations.
The spearman rank correlation coefficient is

Being $(X_1 , Y_1 ),\dots, (X_n , Y_n)$, assign a rank where $(R_1 , S_1 ), \dots , (R_n , S_n )$ for n being all the variables which:

$$
R_s(X,Y) = \dfrac{\sum_{i=1}^n (R_i - \bar{R}) (S_i - \bar{S} )}{\sqrt{\sum_{i=1}^n (R_i - \bar{R})^2}\sqrt{\sum_{i=1}^n (S_i - \bar{S})^2}}
$$

where $\bar{R}=\dfrac{1}{n}\sum_{i=1}^n R_i$ conversely to S: $\bar{S}=\dfrac{1}{n}\sum_{i=1}^n S_i$.
The distribution of the Spearman correlation coefficient is symmetric around 0 and can be approximated to a normal distribution as $\sqrt{n-1}R_{s(X,Y)} \sim N(0,1)$ which can be used to calculate the p-value of a given estimation.

#### MCIA

To find relationships between microorganisms and genes multiple co-inertia analysis, also known as MCIA, was used.
It is a method to examine covariant gene expression patterns between two blocks [@meng2014] provided by the package [omicade4](https://bioconductor.org/packages/omicade4).
MCIA maximizes the following formula:

$$
\sum_{k=1}^K w_k{cov}^2 (X_kQ_ku_k, v)
$$

where $K$ is the total number of matrices, $X_k$ the transformed matrices and $Q_k$ is a square matrix with $r_{ij}$ in diagonal elements indicating the hyperspace of features metrics, $u_k$ are auxiliary axes, $v$ the reference structure and w the weights of the matrices.
This can be used to obtain a dimension of $P_k^d=u_k^d(u_k^dQ_k{u_k^d}^T)^{-1}u_k^dQ_k$ given that for each dimension the residuals are obtained following $X_k^{d-1}=X_1^d-X_1^dP_1^{d-1}$ where $d$ are the dimensions needed.

It was used as a baseline method to compare the RGCCA integration.

#### STATegRa

To explore how much do different blocks of a dataset have in common [STATegRa](https://bioconductor.org/packages/STATegRa) was used [@planell2021].
It is a framework for integrating datasets with two data types using parametric and non-parametric methods.

#### BaseSet

When evaluating a model using bootstrap, [BaseSet](https://cran.r-project.org/package=BaseSet) was developed and used to find which variables were really involved on the interaction and how likely were to be together.
It is a package that uses fuzzy set logic for easy calculation of probability to belong to a group.

A set $S$ is a group of elements for which each element $e$ has an $\alpha$ membership to that set.
$\alpha$ is usually limited between 0 and 1: $\alpha \in [0, 1]$ .
A given element $e$ can belong to more than one set.
Assimilating the membership function to probability we can calculate the probability of a given element $e$ to belong to a set $S$ and not any other set: $P(e \in S|e\not \in S^c)$.
Which applied to the data and case at hand is the probability that a given variable is associated with a given outcome and not with any other outcome.

The membership function was derived from the bootstraps used for each model on the thousand iterations of the integrative method applied to give an estimation of how probable is a given gene and bacteria to be selected as relevant for the model.
With the probabilities of the bootstraps it was used to calculate (via `set_size`) the genes and bacteria that are specific of the model that allows to separate the transcriptome by its location and the microbiome by the disease status.

#### experDesign

[experDesign](https://cran.r-project.org/package=experDesign) was developed [@revillasancho2021] to prevent and quantify if a given experiment has batch effect due to the batches used to measure the values or other known variable.
It might help to detect a bad design of the experiment.

On pseudo code the core of the program can be described as:

``` {#pseudocode-experDesign}
for each index:

    for each batch

        pick size(batch) samples

        if samples are in another batch

            pick other samples

    for each batch

        calculate some summary statistics

        compare with the summary statistics of all the samples

keep the index with less differences between the index and all the samples
```

It can take into account spatial distribution provide which technical replicates[^methods-2] are best given the number of samples that fit on a batch.

[^methods-2]: Thecnical replicates are samples that are measured multiple times to ensure the accuracy of the measurement.
    In contrast biological replicates are sample with the same conditions but different individuals or process before the measurement.

experDesign was used avoid batch effect on the sequencing of the BARCELONA dataset and evaluate them after it was sequenced.

#### ROC- AUC

To estimate if the selected features (genes or microorganism) by the integration methods have some biological meaningful contribution I measured if they can classify features, such as, which gastrointestinal segment is each sample from, or which type of disease does each patient have.

To compare between different models using the receiver operating characteristic (ROC) curve and the area under the curve (AUC) of said curve was calculated with the [pROC](https://cran.r-project.org/package=pROC) package [@robin2011].
It is based on the following formulas, where $FP$ is false positive, $N$ is a negative, $P$ is positive, $TP$ is true positive and $FN$ is false negative:

$$
FPR = \frac{FP}{N}=\dfrac{FP}{FP+TN}
$$

$$
TPR = \frac{TP}{P}=\dfrac{FP}{FP+FN} 
$$

The ROC curve is that where the true positive rate (TPR) or sensitivity, recall or hit rate is represented against the false positive rate (FPR) on the x axis.
The area under this curve is a measure of how good such classifications performs overall.
The higher it is to 1 the better as it classifies incorrectly less samples and accurately classify them.

#### RGCCA

The main method used on this thesis has been regularized generalized canonical correlation analysis (RGCCA) a method derived from the canonical correlation.
Which is a method that uses data from the same sample but from different datasets.
Regularized generalized canonical correlation analysis is implemented on the homonymous package [RGCCA](https://cran.r-project.org/package=RGCCA) [@tenenhaus2017a] which was used on this thesis.
The method and implementation will be explained in detail on the next section.

## Regularized generalized canonical correlation analysis

The regularized generalized canonical correlation analysis is an extension to the canonical correlation analysis [@jordan1875; @hotelling1936] which is an old method to find agreement between two, or more, scorers (as it was first introduced on the literature).

Over several years of progress on the field of canonical correlations [@tenenhaus_component-based_2008; @esposito_vinzi_bridge_2010; @tenenhaus_regularized_2011; @tenenhaus_regularized_2014; @tenenhaus_variable_2014; @tenenhaus_kernel_2015; @gloaguen2020] RGCCA emerged with a regularization step and an extension to more than two scorers.
As previously methods did not have the hability to integrate more than 2 sources of data as does RGCCA [@R-RGCCA].

### Description

The required data are numeric matrix, as big as you want, as it is designed for datasets with more variables than samples ( $p \gg n$).
It needs to have a complete case with no missing values (at the time of writing this thesis there is a [new development version](https://github.com/rgcca-factory/RGCCA/tree/CRAN "RGCCA repository on github") not released on CRAN[^methods-3] yet that replaces any missing value by a 0) and time is not considered as a special variable.
Data should be from the same samples and it is not specific to a certain technology or method used to obtain the data.

[^methods-3]: CRAN is The Comprehensive R Archive Network available at <https://cran.r-project.org/>

It uses a dimensional reduction approach to relate the different data sets between them and produce specific factors for each dataset.
The interpretation of the RGCCA results is complex and require expertise and familiarity with the technique used and is highly dependent on the model and options used.

The authors realized that there is a special problem due to sparsity on biological data which could be handled using first another normalization to improve the stability and success of the canonical correlation methodology.
To perform the dimensional reduction using the sparse method , the method consist on maximizing this function:

$$
\underset{a_1,a_2, \ldots,a_J}{\text{maximize}} \sum_{j, k = 1}^J c_{jk}g(\mathrm{cov}(X_j a_j, X_k a_k)) \mathrm{~~s.t.~~} \Vert a_j \Vert_2 = 1 \text{ and } \Vert a_j \Vert_1 \le s_j, j=1,\ldots,J
$$

Being $X_j$ the values for sample $j$, the weights of the variables of said sample are represented by $a$.
While $g$ is a function that can take the form of $x$, also known as Horst method, $\Vert x \Vert$ known as centroid method, $x^2$ known as factorial method, or any user-supplied function.
The smaller the $s_j$, the larger the degree of sparsity for $a_j$.
As $s_j$ is closer to 0, more features are selected as it looks to optimize covariance, while if it is closer to 1 less features are selected and it resembles the correlation.
The values of $s_j$ were estimated using [@schäfer2005] when the block was from 16S data or RNaseq, otherwise 1 was used.
The shrinkage is defined as:

$$
\widehat{\lambda}^{\star} = \dfrac{\sum_{i\neq j}\widehat{Var}(r_{ij})}{\sum_{i \neq j}r_{ij}^2}
$$

Where the $r_{ij}$ are the correlation coefficients of the matrix between variables $i$ and $j$ .
Where the variance is defined as:

$\widehat{Var}(S_{ij}) = \dfrac{n^2}{{(n-1)}²}\widehat{Var}({w}_{ij})=\dfrac{n}{{(n-1)}^3}\sum_{k=1}^n(w_{kij}-\overline{w}_{ij})^2$

And its components are: $w_{kij}=(x_{ki}-\overline{x}_i)(x_{kj}-\overline{x}_j)$ and $\overline{w}_{ij}=\frac{1}{n}\sum_{k=1}^nw_{kij}$ representing $x_{ij}$ the values of a sample $j$ on a variable $i$.

There are different $g$ functions that could be used but the centroid method was chosen to detect both positive and negative relationships without more computational costs.

Categorical data was encoded as binary (dummy) variables for each factor except one to keep degrees of freedom, where 0 indicates not present and 1 indicates present omitting one level.
Each block, regardless if it had continuous numeric variables or dummy variables was standardized to zero mean and unit variance.
Later, it was divided by the square root of the number of variables of the block for an unbiased estimation.

### Results

RGCCA as other dimensional reduction techniques provides specific weights for each variable on each dimension and a sample score on each dimension, together with quality scores.

To measure the quality of the model, the implementation provides indicators based on the Average Variance Explained (AVE): it returns an AVE score for each block, an AVE score which measures how each variable correlates with their block component, an AVE score of the inner model, which measures how each dimension accounts for the variance.
The higher the score is to 1 the better does it work.
However, that mathematically works better doesn't mean that it have more biological meaning or that it provides more insights on the biology.

### Models

There is no formal definition of what constitutes a block of data on multi-omics tools.
Most multi-omics and integration tools assume one block for each type of data, such as an essay a survey or an experiment.
We decided to split the block with data about the samples to separate independent variables from the same block.
The hypothesis we made was that more blocks with highly related variables but independent from the other blocks would fit better the data and thus help to identify causal or dependent variables.

To model what might be the relationships between the datasets current practices include using a pre-selected model of relations between blocks.
However, this model might not be accurate and several models might need to be fitted.
To help find the fitting model for the data I created an R package, named [inteRmodel](https://llrs.github.io/inteRmodel/), which helps finding the right model and measure how fit it is for your data via a bootstrapping procedure and the provided AVE scores.

This method was applied to the previously described datasets to find the relationship between microorganisms and the disease.
Following this method:

To provide a ground truth, a model with only the relationships between the two experimental obtained data is analyzed, on what it is called the model 0.
The next model analyzed consists on the relationships between the two experimental blocks and them with the metadata of the samples, that is model 1.
All models that have one block with metadata are from the same family of models 1.

Later instead of a big metadata block, following our theory we split this metadata block on several ones, we have a block for time related variables, another one for location and the other about the people on the study.
This allows to design a model with an expected relationships between these dimensions and help make more interpretable the relationships.
These models are from the family 2.

For each family of models we tested all possible models with weights between 0 and 1 (by 0.1 intervals) to find the best model on each datasets according to the AVE score.

The final models were further validated using a bootstrap approach to measure their accuracy and likelihood on the data available.
