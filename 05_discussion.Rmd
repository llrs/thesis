# Discussion

In this chapter we will summarize the main findings in relation to the broad research community and other work as well as the impact of the results to improve further research in the future or be used on clinical environments.

## Preliminary steps

Quality of the initial data for integration is important for a valid integration analysis.
On RNAseq and 16S analysis the sequencing data quality is important.
On sequencing data it is very important to avoid contamination and have enough amount of data for the analysis.
To avoid contamination it is very important the protocol how are processed the samples before the sequencing.
In addition control samples can be added, a blank to control for extraneous material and a sample with known content to confirm that the sequencing worked correctly.

On bulk RNAseq the extraction procedure and sequencing protocol (Described on methods' section \@ref(processing)) has been setup many years ago and works very well.
Rarely there are problems with bulk RNAseq sequencing and its quality.
On the contrary DNA extraction and 16S sequencing was a new procedure on the laboratory.
Initially it was done with the guidelines and support from collaborators.
We did not include control samples on the first 16S sequencing batches but after some problems we started adding at least blank samples to identify those bacteria that might come with the solvent or be from a contamination on the sequencing facility.
This allowed us to discard contamination sources on later sequencing batches and studies..

We initially processed the 16S data to obtain OTUs.
OTUs were the standard some years back [@callahan2017].
However, OTUs are not comparable between studies even those that use the same primers.
For this reason, and after a suggestion from a reviewer (on the review process of [@revilla2021]), we moved to process later 16S sequencing datasets to obtain ASV.
ASV allow to compare the taxonomic imputation between studies using the same primers.
However, comparing 16S taxa ASV or OTUs is hard and selecting the right tool to compare them is important [@nearing2022].

It is also worth keeping in mind that several species have variable number of 16S rRNA genes.
Higher sequences counts of certain 16S might not mean higher abundance of that species compared to another with lower 16S counts.
However, the exact copy number status may change even within the same bacterial species, making the correction difficult [@louca2018].
It is possible to accurately correct for copy number variation on mock populations where the species and the genomes are known (or at least the 16S rRNA), but harder or impossible on samples whose content is unknown.
To our knowledge there isn't a method to do this yet.

<!--# In addition, there are differences on the sequencing reads depending on the  regions selected to amplify the 16S. It would be better to fully sequence the 16S. -->

Furthermore, the precision of 16S sequencing for classification of taxa is not enough to understand its role on the gut.
Adherent invasive cells, are cells with same genetic content that show different behavior [@nadalian2021].
Those bacteria is known to be present on patients with IBD.
Thus, even with the complete sequence they could be undetected.

Most of these steps were out of my control as they were performed by a lab teammate or by collaborators.
Other concerns are currently unavoidable or could not have been found beforehand.

### The datasets {#discussion-datasets}

There is not a methodology to calculate the size of cohorts for interaction or multi-omic studies.
There are no clear rules about which alpha power or which kind of relations are tested.
This might be due to a lack of mathematical background and modelization of the relations on the biological field.
Further research on this area might help finding which kind of relationships can be found given certain dataset size.
In addition to the highly local and not generalizable interactions that happen on biological samples.
Usually size of the datasets is determined from practical reasons: either costs or patient recruitment on protocols.

There are some efforts to simulate multi-omic datasets [@martínez-mira2018; @chalise2016; @chung2019; @patuzzi2019; @fritz2019; @fu2021; @frazee2021; @mccarthy2012].
They usually focus on RNA-seq, ATAC-seq (DNase-seq), ChIP-seq, small RNA-seq, Methyl-seq or proteomics but not 16S or microbiome data.
To my knowledge there is no accurate generator of 16S datasets or other microbiome datasets.
This made impossible to simulate and compare different tools on a similar synthetic dataset with known relationships to evaluate their performance.

There is not a golden dataset for integration.
There are many possible relationships between variables and different ways these relationships might be: regulated DNA, protein recruitment, transcription factors, siRNA regulation.
Not a single one can be measured on a sufficiently detailed timescale that it can show those changes.
As a result we are left with guessing what are the the relationships between variables or their more general patterns.
In addition, this is compound by the lack of explanations about how this relationships might be, despite other indications.

Comparing different datasets is complicated because each is collected with different goals and processed differently.
In addition, there is not a resource were datasets of publications are collected or the relationships between different datasets is not shared.
Authors upload their data to different, not centralized, data repositories, such as, gene expression omnibus ([GEO](https://www.ncbi.nlm.nih.gov/geo/)), European Genome-Phenome Archive ([EGA](https://ega-archive.org/)), European Nucleotide Archive ([ENA](https://www.ebi.ac.uk/ena/browser/home)), among others.
Authors might provide the processed data as supplementary material on their articles.
Some projects whose primary purpose is providing data for the community establishing their own dedicated sites to store the data [@humanmicrobiomeprojectconsortium2012].

Finding different datasets for very similarly data is very difficult.
And once it is found there might be batch effects between them.
There are tools to overcome this, but currently only work if they share some features or samples in common [@ugidos2020].
This usually means having undergone similar RNA sequencing procedures.

All this made finding annotated, appropriate and similar datasets difficult.
We looked up for the most similar datasets in order to be able to confirm our results outside our own cohorts.
Regardless we found several with 16S data and RNAseq from the intestine, that made it possible to compare with our own datasets.
On this thesis there were two datasets collected and sequenced: the HSCT and the BARCELONA dataset.

As explained on methods' section \@ref(methods-hsct), the HSCT dataset is a very special cohort of patients undergoing hematopoietic stem cell transplant.
This treatment is reserved to patients whose all the other treatment failed and this is the only way to reach remission.
This is common on patients with long time CD.
These patients are highly characterized and there is follow up data for several years.
However, it does not include UC patients and they are not representative of IBD, or even CD, patients.\
On the HSCT dataset microbiome features were OTUs.
OTUs can not be imputed afterwards to ASV.
As such, the annotation of the 16S data is not the same as in the others datasets.

The BARCELONA dataset (See appendix section \@ref(barcelona)) includes samples from CD and UC of an ongoing study.
Similar to the HSCT dataset, patients on this study were followed up for up to a year.
Patients were younger and had less years with the disease, which could provide with more insights on the initial relationships between the microbiome and the mucosa of IBD.

However, the data quality of BARCELONA was not good enough to make reliable analysis and confidently extract hypothesis or relationships (See appendix section \@ref(barcelona)).
It is not clear what happened and as a consequence it is not clear how to avoid such problems on the future.
It could be a problem of the original DNA extraction and/or of its sequencing process which did not include both positive and negative controls.

What happened with the BARCELONA dataset -and the organoids cohort not described here- highlights the importance of data quality checks.
On the BARCELONA cohort despite no batch effect or other quality issues with the data as checked with `experDesign`, the diversity indices suggested that there was some problem with the microbiome data.
This made us not trusting the data and not using it for data integration.
The organoids cohort is a dataset that was sequenced following the `experDesign` recommendations for distribution of samples on different batches.
However, a batch effect was found.
The batch effect was created on the lab process before the samples' were sequenced.
Caution and a good relationship with the sample and data generator is important to discover these kind of problems and ensure the quality of the data.

Other datasets used from published sourced were assumed they had already passed enough controls and had a good quality.
Nevertheless, they were screened to avoid quality issues.

The Puget's dataset dataset provided a good benchmark to test the methods and understand how RGCCA works.
CNV/CGH is a completely different type of data than microbiota, but the microarray data is similar to the RNAseq data from other datasets.
We were not as much interested on the biology as on learning about the RGCCA method and possibilities of integration with it.

Häsler data were obtained using the same sequencing techniques from endoscopic biopsies as our dataset HSCT and Barcelona and it is of the same disease.
The 16S data was very similar to the HSCT dataset.
We could confirm that the inteRmodel approach works on more than one dataset.

The taxonomy of the different datasets was done differently.
After the first two datasets SILVA database was used to annotate the microbiome data on their corresponding taxa.
On HSCT following our collaborators advise we used other methods to annotate its microbiota data.

Morgan's dataset is related to IBD but it is from a cohort of patients that underwent colectomy and samples are specific of the pouch or pre-pouch ileum, there are no healthy samples and there is no follow up.
It made very unlikely that a classification of the location could be achieved and the classification of the samples according to the microbiota could not be based on the disease (as all of them had undergone the same procedure with the same disease).
There seems to be gradation on the models on \@ref(fig:morgan-models) that could partially be explained by different degrees of inflammation.

Howell's dataset includes both CD and UC (and non-IBD) samples.
It is very similar to our BARCELONA dataset but on pediatric cases.
As expected time with the disease of these patients is much lower, and they have might followed less treatments and probably have not had any surgery.
However, they were not followed up at different time points.

### The methods

As seen on the introduction there are many different methods are available.
There are frequent releases of new tools and methods.
The most up to date list of tools might be added to a [collaborative list](https://github.com/mikelove/awesome-multi-omics "Awesome multi-omics list").
Methods are very different in how they can be used and how they can be classified.
The quality of the software and methods also differs.
Some of them were tested on several datasets but their most important validation process undergone is the mathematical validation they have and its correct implementation.

With the increase of tools there have been increasingly important to compare different tools.
There are reviews of different tools on the same datasets [@cantini2021], some are more theoretical [@bersanelli2016], others are focused on a different field [@cavill2016].

Of all these methods very few have been applied on IBD datasets.
Recently there has been an article focused on integration on IBD [@sudhakar2022].
On this publication the authors suggest that one must be mindful of the gap between the experimental conditions and the real world.
It also encourages to collect more data about the exposome (the stimuli patients have).
It ends up advising to set up guidelines for multi-omic studies tailored to the field, coordinate in a global framework to prevent redundant studies and ensure efficient funding and resources and disseminate training and education on computational approaches to analyze multi-omic datasets.

Current methodological approaches focus on comparing tools on (several) previously published datasets [@cantini2021], an approach that we have taken too.
This approach was not used to compare different tools, we also did it, but to validate findings of one dataset in other datasets.
This is specially important due to the lack of golden datasets or a way to reliable simulate datasets as discussed on the previous section \@ref(discussion-datasets).

On IBD, many studies focus on finding some genes or bacteria to answer a narrow question they have in mind, like which bacteria is related to inflammation [@tang2017]. On this thesis, the focus was on finding a good representation of the relationships that allowed to identify genes and bacteria are relevant on the disease. We made the assumptions that microbiome presence and transcriptome are related. This assumption is backed up by several other previous studies supporting this relationship [@holmes2012; @stappenbeck2002; @brand2021; @cornish2008; @thomas1998].

Tools that relate the variance of a block with other variables, both numeric and categoric, are needed to search which variables are important.
PERMANOVA and `globaltest` identified which variables were important.
But they do not give any insight into which specific microbial species are driving the association between the microbiome and the variables [@susin2020].
In addition, we could miss some other important variables.
It is known the role of other factors outside the omics data collected, mainly from environment factors, genetic susceptibility and immune response [@sartor2006].
Sudhakar *et. al.* [@sudhakar2022] recommend being conscious of the gap between the data available and the biological process.
However, even if we missed them, we probably have not collected it or it is not available, there is nothing at this point that can be done.
This would be in conflict with a data protection principle: collect the minimum sufficient information needed.
We might not identify a relevant variable but to identify it we would need to collect too much information from the patients and for little or no clear benefits.
One variable we did not keep track was the microbiome load which is linked to the gut's microbiome community variation [@vandeputte2017].
We did not measure it because at the time of extraction we didn't quantify the cells present and after the DNA extraction it was too late.
To our knowledge this is not usually done and several other studies lack this data.

We tried to find which genes and bacteria are correlated between them using `WGCNA`.
It is a tool designed to find common co-occurring patterns based on correlations.
It requires homogeneous samples, with a minimum of 12 samples per condition.
When applied to the whole dataset there might bee too much variance in order of WGCNA to find the proper signal.
As we have patients of different ages and location which is highly related to the intestinal microbiota this might be the reason why it failed to achieve a good fit on the scale free topology with around 100 of mean connectivity.
In addition, having microbiome and RNASeq on the same matrix, would probably be hard for the process to find good relationships if we applied the same normalization process to both of them without escalation.
We could have tried to make smaller groups and then compare the modules between them but it groups would be too small because samples were from multiple segments and conditions.

We briefly considered using `STATegRa` but it is not possible to select which interactions between the blocks exists and by that time we already knew it was important to consider several of the variables collected from the patients.
The method implemented on `STATegRA` might be useful for cases where there is a great agreement between blocks or were the variables of the samples are not so important as with our data.

To identify related variables other methods use correlations between the variables [@vila-casadesús2016].
On our dataset we visually explored the correlations for all the datasets, but the significant correlations were usually driven by an outlier, or was not a good fit of the data due to missing microbiome presence (data not shown).
We tried filtering correlations from those identified by the models, being less restrictive on the significance of the correlation, removing those samples that did not have microbiome presence on at least 5 samples, and remove those samples without that microbiome presence and splitting by location and a combination of all these.
All of these variations didn't provide a clear insight over which genes were correlated to which microbiomes, this differs to other publications that relied on them to draw their conclusions [@häsler2017].
This might be due to them relying purely on the Spearman $\rho$ metric instead of visualizing the correlation it measures or having more common microbiota between the samples.

We developed `BaseSet` to find these relationships using a different approach.
`BaseSet` did not work for its intended usage on this thesis.
It failed because it is computationally expensive to calculate the likelihood of 1500 variables; there are too many combinations.
In addition, the numeric precision of said calculations suffers from the floating point problem and must be carefully considered [@goldberg1991].
To support multiplying more than 1000 float numbers a different strategy such as using log values might be better.
We could not come up with a better strategy to find all the combinations needed, perhaps a better method exists that could be used to find which are the terms more influential to the end result.
During the peer-review process of the package for its acceptance on rOpenSci, some concerns were raised about conflating probabilities with fuzzy-sets.
For all these reasons this approach was no longer pursued.
However, the package was mentioned as [top 40 packages](https://rviews.rstudio.com/2020/12/22/november-top-40-new-cran-packages/) added on CRAN that month and it will be useful on other circumstances or when less combinations are possible.

The development of the `experDesign` package helped avoid batch effects on the sequencing step.
However, as seen on the previous section, this does not prevent all problems with batch effects and still batch effects resulting on a less useful experiment might get through.
As discussed on the related publication, there are several tools already focused on this problem: `OSAT` (@yan2012), `anticlust` (@papenberg2020) and `Omixer` (@sinke2021).
But these tools have some shortcomings, that are covered by `experDesign`: `OSAT` cannot handle missing values and does not work well for arbitrary batches, `anticlust` only accepts numerical variables but it is based on a powerful mathematical theorem and `Omixer` has bugs that prevent comparing with the other tools with no possible workaround.\
In addition, `experDesign` received [requests](https://github.com/llrs/experDesign/issues/22#issuecomment-1033508578) to have a new feature for expanding experiments.
This might help improve the quality of bigger datasets to ensure they can be extended in several sequencing runs.
This feature would be useful for multi-omics datasets or in big cohorts to minimize batch effects associated with long running collection of samples.

We selected `MCIA` as a baseline to compare our method because it works well on a wide range of datasets, has a good documentation as well and it is fairly widespread used.
The method was developed after `RGCCA` and recently there have been publications that show that it outperforms other methods on its versatility on different contexts [@cantini2021].
On the dataset analyzed we found it was very competitive with `inteRmodel` but this will be discussed on section \@ref(evaluating-models).

## Designing models

Previous publications using `RGCCA` on IBD focused on validating inflammation markers genes *DUOX2* and *APOA1* as inflammation predictors (@tang2017) from previously published articles [@haberman2014].
Some publication tried to summarize the existing relationships on IBD [@hasler_uncoupling_2016], but none were focused on finding the existing relationships on IBD using `RGCCA` as we did.

There are many variables outside transcriptomics and microbiome that are relevant to the disease (and healthy) homeostasis.
These variables should be included on the models to find which genes and bacteria are really related and not confounded by other factors.
In addition, the relationships between the blocks are unknown on both the strength and interaction.
To model the relationships the connections between blocks had to be set on `RGCCA`.
Last, what belongs to a block should be carefully considered as the assumption is that the whole block is correlated with other blocks connected.

If one has preexisting theories about the data, a specific model can be used stating these known or hypothetical relationships.
However, if new relationships are being explored or no prior beliefs on the data are held the models should be created with random links between blocks, and evaluate which model is better.

The connections tested required that all models should have all blocks indirectly connected to other blocks; no isolated blocks left.
This avoids optimizing two different networks of blocks that are not connected between them.
Thus, forcing the model to represent all the information.

Typically blocks are defined by each omic data origin and no other information is included.
However, we knew that the transcriptome is mainly related to the location of the samples and we expected that the microbiome would be more related to the variables related to the patients demographic characteristics and dietary and personal habits.
This is specially important because in our datasets we have samples from the same patient and time from multiple locations.
On other studies there are less samples per individual and timepoint (if there are several timepoints) [@howell2018; @hasler_uncoupling_2016; @morgan2015].

On models of family 2, variables of samples were separated according to what they are.
If it is about the individual it would be on the Demographic block, if it is about time on a Time block, and if about the location of the sample on a Location block (c.f. with tables on design of Puget's \@ref(tab:puget-model2-2), \@ref(tab:puget-model2); HSCT \@ref(tab:hsct-model2) \@ref(tab:hsct-model2-2), \@ref(tab:hsct-model2-3); Häsler: \@ref(tab:hasler-model-2-1), \@ref(tab:hasler-model-2-2), Morgan's \@ref(tab:morgan-model2), \@ref(tab:morgan-model2-2), Howell's \@ref(tab:howell-model2-2) models).

The exploration of design on Puget's dataset, and the datasets analysis of HSCT, Häsler and Morgan's dataset was published after peer review [@revilla2021].

## Evaluating models

To evaluate a model `RGCCA` provides the average variance explained (AVE), inner and outer (see section \@ref(rgcca-output)).
As we are more interested on the model of the relationships the inner AVE makes more sense to evaluate it.

<!--# TODO Add tables of mean and sd of AVEs on the bootstrapping ? -->

Furthermore, bootstrapping was used to evaluate the fitness of a design on a diverse collection of datasets.
Although on `inteRmodel` there is the option to use a leave-one-out procedure, we didn't use it to evaluate the fitness of the models.

Using an external cohort to validate the same model, or using a different method to see if it finds the same relationships or explains the data as accurately is also a common approach to evaluate and validate models.
Using the same approach on different data helps to ensure the replicability of the results [@community2021].

```{r reproducible-matrix, fig.scap="Reproducibility matrix", fig.cap="Reproducibility matrix indicating the terminology used between using the same method and the same data. Figure from The Turing Way: A Handbook for Reproducible Data Science (Version v1.0.1)."}
include_graphics("images/turing_way_reproducible-matrix.jpg")
```

We used the same approach on 4 different cohorts, from different origins and with different types of samples, but all are related to IBD, have 16S data and intestinal transcriptome.
Some of them have multiple samples from the same individuals while others do not [@hasler_uncoupling_2016].

We also compared our method with a different one to see how generalisable are the results.
Of the multiple methods available we used [`MCIA`](https://bioconductor.org/packages/omicade4 "Omicade4 package") [@mengMultivariateApproachIntegration2014].
We compared it with `inteRmodel` by looking at the area under the curve for classifying the samples with the canonical component of the transcriptome data according to their location.

The procedure of separating independent variables in their own block of data and later search the best model that fits the data provides a good strategy that should be consider for integration efforts.
The procedural method of searching a model and testing them is implemented on [`inteRmodel`](https://llrs.github.io/inteRmodel/ "inteRmodel").
But the most important thing is to consider which variables are independent of which and if they can be separated into a block for later usage on the modeling (See @pearl2011).
If not done properly it can lead to undesired conclusions like the effect known as [Simpson's paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox) [@simpson1951].
Unfortunately this cannot be automated and it is left for the practitioner.

Splitting the variables of each sample into several blocks forces `RGCCA` to adjust for a new canonical dimension.
The omics block such as gene expression and 16S data could be split, as the expression of some genes influence other genes, such as [transcriptor factors](https://en.wikipedia.org/wiki/Transcription_factor) (First mentioned on @stillman1984) , [miRNA](https://en.wikipedia.org/wiki/MicroRNA) [@lee1993], [siRNA](https://en.wikipedia.org/wiki/Small_interfering_RNA) [@hamilton1999]... All these interactions and regulations could distord the canonical correlations.
However, the nature of this relationships is not linear and the interaction between them is multiple and very complex.
Its complexity has prevented to accurately account for all subcellular reactions at speeds that could be useful (it has only been recently accomplished for a prokaryote cell [@thornburg2022]).
In addition, these interactions are time dependent, not linear and are highly interconected between a large number of variables.
For these reasons gene expression and 16S block were not split into several blocks.

Besides comparing the results of different methods, these models need to be evaluated by the insights they provide on the biological system they are being applied to, in our case IBD.
So far the models were only discussed on their technical merits.

It is known that mucosal transciptome is related to localization of the samples [@criss2021].
This can be seen on the PCAs which separate colon an ileum on the first dimension: See the PCAs of the different datasets \@ref(fig:hsct-pca-rnaseq), \@ref(fig:hasler-pca-rnaseq) and \@ref(fig:howell-pca-rnaseq).
The difference is so great that many times the colon and ileum samples are analyzed separately.
As such, it was a reasonable assumption to expect models to reflect this differences on the gene expression canonical component.

The variability of microbiome challenges finding clear patterns (See the PCAs of the different datasets: \@ref(fig:hsct-pca-16s), \@ref(fig:hasler-pca-16s), \@ref(fig:morgan-pca-16s) and \@ref(fig:howell-pca-16s)).
On healthy humans, it has been suggested that there is a common microbial composition on all humans [@arumugam2011]. Such theory suggests three groups of similar microbiota composition, named enterotypes. However, the enterotypes classification is not unanimously accepted [@koren2013; @cheng2019].
Some suggest it is an artifact of the metodolody used.

There are many factors that influence the gut microbiome [@hasan2019]. But the role of microbiome on IBD has recently gained some interest [@khanna2014; @bringiotti2014; @lloyd-price2019].
It has been associated with predictors of CD treatment response and suggested that they could be useful for building an improved classifier for CD and treatment response based on sufferers' microbiome in the future [@douglas2018].
Thee is for instance, an association between IBD and butyrate producers (See [@takahashi2016]) which has shown to influence permeability of the epithelial barrier [@ferrer-picón2020].

In addition, it is known that microbiome of patients in remission is different from non-IBD patients [@halfvarson2017].
So even if two people seem healthy at this moment their microbiome might not be similar.

The relapse nature of IBD, suggests that at different time points the gene expression or the microbiome might be different.
For this reason, time is an important variable when modelling the disease.
If multiple timepoints are taken they should be taken into account to identify the state of the disease for each patient.
Even on healthy non-IBD patients, multiple samples with microbiota from the same patients could provide a common microbiome background, which can help to identify core individual microbiome and altered microbiome states later on.

On the cohorts analyzed on this thesis, only the HSCT and the Häsler dataset had some time related variables available.
However, Häsler dataset only had age at date of sampling, and there were not several samples for the same patients at different timepoints.
This leaves the HSCT dataset with the only one with multiple timepoints from the same patients.
Having that many samples from the same patient might explain why the classification of the disease on this cohort works so well, with relatively a very complicated cohort with several background treatments, refractory to all previous treatments , some of them having undergone surgery too and with wide systemic changes.
Despite all of this there was a huge agreement in genes identified as relevant between datasets and the pathways identified are relevant to the intestine (See section \@ref(fig:pathways-hsct-howell)).

Comparing microbiome between datasets is less straight forward.
If the same primers are used the ASV could be directly compared.
However, the ASV' length might be different.
In addition, on this thesis we used dataset with different primers and also OTUs.
For these reasons a direct comparison is not possible.
A comparison of the taxonomy of the annotated microbiome on the datasets is the next possibility.

However, some datasets used did not provide the annotation (Häsler's and Morgan's dataset).
We have two dataset with annotation of the microbiome on the taxonomy, our own HSCT dataset and Howell's dataset.
So we are are left with comparing OTUs with ASVs.
Despite the errors on ASV annotation ( @edgar2018), OTUs from the HSCT dataset can be compared to ASV from Howell's dataset.
There were very few common taxonomic levels selected on both datasets (data not shown).
This was not a surprise, as there are many factors that influence one's microbiome profile and the diversity indexes already showed high differences between samples of the same dataset.

The microbiome of each dataset seem capable to classify the samples according to the disease (data not shown).
However, on further evaluation via bootstrapping this resulted not significant, as any relatively big amount of microbiome variables might classify the samples due to their specificity.

On Howell's and Häsler dataset, the best model is 1.2; which separates the microbiome component by location too (See Figure \@ref(fig:hasler-models) and table \@ref(tab:hasler-aves) for Häsler dataset and figures \@ref(fig:howell-models) and table \@ref(tab:howell-models-ave)).
Those models 2.2 according to the inner AVE are not that far away from models 1.2.
Which seems to imply that the relationship of the microbiome is slightly stronger with the location than the relationship with the disease.
Both factors should be considered when looking for relationships of genes with microbiome.

## Implications

On this thesis several methods has been developed for helping research.
`experDesign` is on the primary steps from moving from the bench to the in-silico experiments.
`BaseSets` and `inteRmodel` are more relevant for computational analysis.
`BaseSets` might help beyond integration analysis such as single cell annotation[^discussion-1].

[^discussion-1]: See an exploration of this using AUCell <https://bioconductor.org/packages/AUCell> on this website: <https://llrs.github.io/BaseSet_scRNAseq/AUCell.html>.

Some studies using host transcriptomics of fecal wash infer inflammation without colonoscopy [@ungar2022].
This would help patients to avoid an unpleasant experience, and reduce the usage of clinical facilities.
It could be possible that just sequencing the intestinal microbiome could be enough to identify the patients' disease.
However, this requires further validation to ensure that the diagnosis is accurate enough on a diverse and big population.
There are already studies on this direction, not only for IBD or intestine but for several different human regions [@humanmicrobiomeprojectconsortium2012].

With these studies we hoped that they would provid which bacteria played a role on the disease, or which genes and bacteria are related on IBD.
We obtained a list of putative genes and bacteria but not a clear pairing of which genes interact with which bacteria.
This could mean that the microbiome community is related to all the genes.
It could also mean that the methods are not powerful enough to find more tailored relationships as normalizations and generalizations present on `RGCCA` do not allow to subgroup or classify the variables already detected.
Maybe a different method that would not depend on the same principles might be able to detect finer relationships on the variables selected.

There is a disconnect between the computational side and the experimental side, driven by the difficulty to think an experiment to test the new information that multi-omic experiments provide.
This is referred as the gap in other publications [@sudhakar2022].
This gap between the computational methods and the data origin and practical usages should close.
Potentially this would require more closer collaboration between clinicians, statisticians, bioinformaticians and research software engineers; in addition to creative ideas accounting for the standard procedure on hospitals and points of care.

However, it is also possible that further developments or creatively applying statistical methods might help closing the gap.
For instance, there are many combinations of interaction possible.
These interactions between microbiome and genes are currently hard to explore statistically.
Further research on how to reduce the space of possible combinations of bacteria or evaluate which combinations are more important might be useful on the future.
This might involve using more network integration methods.

Krassowski's *et. al.* ([@krassowski2020]) advice and recommendations on software engineering and reproducibility practices to share awareness with new researchers in multi-omics for end-to-end workflow.
In addition the recent recommendation about integration on IBD ([@sudhakar2022]) suggests that there is still much to be done to increase the results on these projects and the effectivity.
We agree with them and encourage other researchers to carefully consider the proposed methodology before starting their own projects.

There seems to be a tendency of multi-omics project to focus on metagenomics, metatranscriptomics and metaproteomics and abandon plain 16S sequencing [@zhang2019].
This could be explained by the numerous problems that 16S sequencing have.
Some of these are avoided or solved by using these other omics techniques.
For instance the metatranscriptomics and metaproteomics could help detect what is actively producing the microbiota and the metagenomics, what is actually there at a more detailed level than 16S.
But these methods also have their shortcomings.
Metagenomics still does not detect adherent invasive cells and metatranscriptomics and metaproteomics do not provide who is producing what (even if paired with metagenomics or 16S data).
Devonvoluting which bacteria produces something is also not clear.
The single cell revolution might provide more insights in the future, but at the moment the first studies of single-cell multi-omics are being published.

Perhaps as suggested in other publications network methods might be able to provide more detailed information about the relationships [@jiang2019].
But, it is unclear how complete and valid are these networks.
There is some evidence that currently literature focus on already known and studied genes instead of more novel and with higher relevance genes [@haynes2018].
By extension, this translates in bias in networks and pathways resources available for pathway analysis and integration methods.
This could explain why there are many genes selected by the models with few pathways or gene sets.

To study complex systems, new technologies like "organ-on-chip" or more specifically "gut-on-chip" are being developed [@collij2021].
These systems expand on the already useful technique of using organoids to better mimic the epithelial cross-talk on the laboratory.
Latest developments include the addition of separate environments and distinct flow on these environments.
By introducing gut microbiota, these systems will help studying the interaction of the gut microbiota and the intestinal epithelium.
However, it is not clear how accurately accounts for other factors such as the accumulation of inflammation.

As shown with the PERMANOVA approach, several factors affect the disease and the relationship between gut's microbiome and gut's mucosa.
Analysis or comparisons without taking into account them might provide misleading or false results.
To our knowledge this is the first study using these variables as part of the integration study with canonical correlations.
We hope this provides a first approximation to accurately understand the relationships between genes and bacteria on IBD.
