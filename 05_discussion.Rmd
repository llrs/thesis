# Discussion

In this chapter we will summarize the main findings in relation to the broad research community and other work as well as the impact of the results to improve further research in the future or be used on clinical environments.

## Preliminary steps

Quality of the initial data for integration is important for a valid integration analysis.
On RNAseq and 16S analysis the sequencing data quality is important.
On sequencing data it is very important to avoid contamination and have enough amount of data for the analysis.
To avoid contamination it is very important the protocol how are processed the samples before the sequencing.
In addition control samples can be added, a blank to control for extraneous material and a sample with known content to confirm that the sequencing worked correctly.

On bulk RNAseq the extraction procedure and sequencing protocol has been setup many years ago and works very well.
Rarely there are problems with bulk RNAseq sequencing and its quality.
On the contrary DNA extraction and 16S sequencing was a new procedure.
Initially it was done with the guidelines of collaborators.
Later, when we did ourselvs we did not include control samples but after some problems we started adding at least blank samples to identify those bacteria that might come with the solvent or be due to contamination.

Once the 16S data was obtained we initially processed it to obtain OTUs.
OTUs were the standard some years back.
However, OTUs are not comparable between studies even those that use the same primers.
For this reason, and after a suggestion from a reviewer, we moved to process later 16S sequencing datasets to obtain ASV.
ASV allow to compare the taxonomic imputation between studies using the same primers.
However, comparing 16S taxa ASV or OTUs is hard and selecting the right tool to compare them is important [@nearing2022].

It is also worth to keep in mind that several species have variable number of 16S rRNA genes.
Higher sequences counts of certain 16S might not mean higher abundance of that species compared to another with lower 16S counts.
However, the exact copy number status may change even within the same bacterial species, making the correction difficult [@louca2018].
It is possible to accurately correct for copy number variation on mock populations where the species and the genomes are known (or at least the 16S rRNA), but harder on samples which content is unkown.

<!--# In addition, there are differences on the sequencing reads depending on the  regions selected to amplify the 16S. It would be better to fully sequence the 16S. -->

Furthermore, the precision of 16S sequencing for classification of taxa is not enough to understand its role on the gut.
Adherent invasive cells, are cells with same genetic content that show different behavior[@nadalian2021].
Thus even with the complete sequence play a different role on the health of the patients.

Largely all these steps were out of my control as they were performed by a lab teammate or by collaborators.

### **The datasets**

There is a lack of methodology to calculate the size of cohorts for interaction or multiomic studies.
There are no clear rules about which alpha power or which kind of relations are tested.
This is due to a lack of mathematical background and modelization of the relations on the biological field.
In addition to the highly local and not generalizable interactions that happen on biological samples.
Usually size of the datasets is determined by practical concerns, either costs or patient recruitment on protocols.

Comparing different datasets is complicated because each is collected with different goals and processed differently.
We looked up for the most similar datasets in order to be able to confirm our results.
Although on each section we analyzed multiple datasets.

On this thesis there were two datasets collected and sequenced.
The HSCT and the BARCELONA dataset.
On the HSCT dataset the ....

On the BARCELONA dataset .
What happened with the BARCELONA cohort and the organoids cohort (not described here) highlights the importance of the quality check of the data.
On the first case it was a clear batch effect that at the time of sequencing it was unavoidable and could not be corrected.
On the BARCELONA cohort despite no batch effect or other quality issues with the data, the diversity indices made impossible using it.

HÃ¤sler data were obtained using the same sequencing techniques from endoscopic biopsies as our dataset HSCT and Barcelona and it is of the same disease/field.
The confirmation that the inteRmodel approach works on it it helped to continue forward.

The taxonomy of the different datasets was done differently.
After the first two datasets it was used the SILVA database to annotate the ASV.

On the HSCT dataset as OTUs were used it could not be imputed afterwards to the same SILVA database without recasting the 16S to ASV.
The annotation of the 16S data is not the same as in the others.
The Cristian's dataset was also imputed with SILVA but using a different database version.

### **The methods**

As seen on the introduction many methods are available.
Some of them were tested on one or several datasets.

If we had to summarize all the work in one sentence we would say that...

Many work focus on finding some genes or bacteria to answer a question they have in mind.
On the thesis the focus was more on finding a good representation of the disease that allowed me to identify genes and bacteria that were relevant to our questions.

There are many methods for integration developed, each with their shortcomings and strengths.
There are frequent new tools and methods released, and the most up to date list of tools might be added to a [collaborative list](https://github.com/mikelove/awesome-multi-omics "Awesome multi-omics list") (from which the appendix table of methods has been taken).

With the increase of tools there have been more pressure on comparing different tools.
There have been already some articles comparing the different tools, which the previous mentioned list also has.
There are reviews of different tools on the same datasets [@cantini2020], some are more theoretical, others are focused on a different field.
Recently there has been a recent article focused on integration on IBD [@sudhakar2022].

adonis and globaltest worked well to identify which variables were important.
But it could be that we missed some other important variable.
However, even if we missed it we probably haven't collected it or it is not available so, no point on trying to find it.

WGCNA did not work well.
It is a tool designed to find common patterns based on correlations requiring homogeneous samples.
Having samples from multiple segments and conditions did not help.
We could have tried to make smaller groups and then compare the modules between them but it probably would not have ended well as the groups would be too small.
Lastly, having microbiome and RNASeq on the same matrix, would probably be hard for the process to find good relationships if we applied the same normalization process to both of them.

MCIA works well as baseline.

STATegRa is not customizable to specific interaction between the datasets.

RGCCA some improvements.

`BaseSet` did not work for its intended usage on this thesis.
It failed because it is computationally expensive to calculate the likelihood of 1500 variables, there are too many combinations.
In addition, the numeric precision of said calculations suffers from the flotating point problems and must be considered carefully.
To support multiplying more than 1000 float numbers a different strategy such as using log values might be better.
We could not come up with a better strategy to find all the combinations needed, perhaps a better method exists that could be used to find which are the terms more influential to the end result.

Some batch effects are avoidable due to the experDesign package.
This might help to improve the quality of the datasets and to expand previously sequenced datasets.

## Designing models

The model of the generalized canonical correlation is highly dependent of the blocks present.

If one has preexisting theories about the data, a specific model can be used stating these known or hypothetical relationships.
However, if new relationships are being explored or no prior beliefs on the data are held the models should be created with random links between blocks, and evaluate which model is better.

## Evaluating models

To evaluate a model RGCCA provides the average variance explained (AVE), inner and outer.
Inner AVE is for how well do all the canonical dimensions correlate with the design of the experiment, so it a measure of how good the model is.
While outer AVE is a measure of how well do the variables of each block correlate with the canonical dimension, so it measures the agreement between the variables and the canonical dimensions.
Depending on the goals of the research one or the other should be used.
If we are more interested on the model of the relationships the inner AVE makes more sense.

Furthermore, to evaluate a design bootstraping can be used to know how well the design does apply to a variety of data.
Another option is to use an external cohort to validate the same model, or using a different method to see if it finds the same relationships or explains the data as accurately.
Of the multiple methods available we used [MCIA](https://bioconductor.org/packages/omicade4 "Omicade4 package") [@mengMultivariateApproachIntegration2014].
Which was compared by looking at the area under the curve for classifying the samples according to their location.

Besides a way to compare methods, these models do need to be evaluated by the insights they provide on the biological system they are being applied to, in our case the Crohn's disease.
In this article we did not look in depth to the biological relevance of the microorganisms an genes found.

The procedure of separating independent variables in their own block of data and later search the best model that fits the data provides a good strategy that should be consider for integration efforts.

The procedural method of searching a model and testing them is implemented on [inteRmodel](https://llrs.github.io/inteRmodel/ "inteRmodel").
But the most important thing is to consider which variables are independent of which and if they can be separated into a block for later usage on the modeling.

Transciptome is related to localization of the samples.

Microbiome is more related to the disease and other variables of the patients.

Time is an important variable when modelling the disease, if multiple timepoints are taken they should be taken into account to identify the state of the disease for each patient.

[@jiang2019] A paper about multi-omics and microbiome...

[@krassowski2020] advice and recommendations on software engineering and reproducibility practices to share a comprehensive awareness with new researchers in multi-omics for end-to-end workflow.

## Relevance for other research

It is hard to provide more information that can be later used by researchers on the wet lab.

Paper about using transcriptomics to infer inflammation without colonoscopy [@ungar2022]

There is a disconnect between the computational side and the experimental side, driven by the difficulty to think an experiment to test the new information that multi-omic experiments provide.

Many combinations possible that are hard to explore, further research on how to reduce the space of possible combinations of bacteria or evaluate which combinations are more important might be useful on the future.
As this might help focus on the most promising bacteria.

## Implications of research

Translational research?
How to apply this results ?

Sequence just the ASV on patients to classify them on disease might be an option that would require further clinical validation.

Selecting which genes are related to the microorganisms is will require also further validation (for which I did not have the creativity to think of).

The several environmental factors highly affect the disease, so analysis or comparisons without taking into account them might provide misleading or false results.

Multi-omics seems to focus on metagenomics, metatranscriptomics and metaproteomics and abandon plain 16S sequencing [@zhang2019].

<!--# From @collij2021 add references/adapt-->

To study complex systems, new technologies like "organ-on-chip" or more specifically "gut-on-chip" are being developed [@collij2021].
By introducing gut microbiota, these system will be of great help in the stud of the interaction of the gut microbiota dn the intestinal epithelium.
