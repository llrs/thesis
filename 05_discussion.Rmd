# Discussion

In this chapter we will summarize the main findings in relation to the broad research community and other work as well as the impact of the results to improve further research in the future or be used on clinical environments.

## Preliminary steps

Quality of the initial data for integration is important for a valid integration analysis.
On RNAseq and 16S analysis the sequencing data quality is important.
On sequencing data it is very important to avoid contamination and have enough amount of data for the analysis.
To avoid contamination it is very important the protocol how are processed the samples before the sequencing.
In addition control samples can be added, a blank to control for extraneous material and a sample with known content to confirm that the sequencing worked correctly.

On bulk RNAseq the extraction procedure and sequencing protocol (On Methods \@ref(processing)) has been setup many years ago and works very well.
Rarely there are problems with bulk RNAseq sequencing and its quality.
On the contrary DNA extraction and 16S sequencing was a new procedure.
Initially it was done with the guidelines and support of collaborators.
Later, we did not include control samples on the first 16S sequencing attempts but after some problems we started adding at least blank samples to identify those bacteria that might come with the solvent or be from a contamination on the sequencing facility.
This allowed us to discard contamination sources on later sequencing shipments.

Once the 16S data was obtained we initially processed it to obtain OTUs.
OTUs were the standard some years back.
However, OTUs are not comparable between studies even those that use the same primers.
For this reason, and after a suggestion from a reviewer, we moved to process later 16S sequencing datasets to obtain ASV.
ASV allow to compare the taxonomic imputation between studies using the same primers.
However, comparing 16S taxa ASV or OTUs is hard and selecting the right tool to compare them is important [@nearing2022].

It is also worth to keep in mind that several species have variable number of 16S rRNA genes.
Higher sequences counts of certain 16S might not mean higher abundance of that species compared to another with lower 16S counts.
However, the exact copy number status may change even within the same bacterial species, making the correction difficult [@louca2018].
It is possible to accurately correct for copy number variation on mock populations where the species and the genomes are known (or at least the 16S rRNA), but harder on samples which content is unknown.

<!--# In addition, there are differences on the sequencing reads depending on the  regions selected to amplify the 16S. It would be better to fully sequence the 16S. -->

Furthermore, the precision of 16S sequencing for classification of taxa is not enough to understand its role on the gut.
Adherent invasive cells, are cells with same genetic content that show different behavior [@nadalian2021].
These microbiome is known to be present on patients with IBD.
Thus even with the complete sequence play a different role on the health of the patients.

Most of these steps were out of my control as they were performed by a lab teammate or by collaborators.
Other concerns are currently unavoidable or could not have been found beforehand.

### The datasets {#discussion-datasets}

There is not a methodology to calculate the size of cohorts for interaction or multiomic studies.
There are no clear rules about which alpha power or which kind of relations are tested.
This might be due to a lack of mathematical background and modelization of the relations on the biological field.
Further research on this area might help finding which kind of relationships can be found given certain dataset size.
In addition to the highly local and not generalizable interactions that happen on biological samples.
Usually size of the datasets is determined from practical reasons: either costs or patient recruitment on protocols.

There are some efforts to simulate multi-omic datasets [@martínez-mira2018].
They usually focus on RNA-seq, ATAC-seq (DNase-seq), ChIP-seq, small RNA-seq, Methyl-seq or proteomics but not 16S or microbiome data.
To my knowledge there is no accurate generator of 16S datasets or other microbiome datasets.
This made impossible to simulate and compare different tools on a similar synthetic dataset with known relationships.

There is not a golden dataset for integration.
There are many possible relationships between variables and different ways these relationships might be: regulated DNA, protein recruitment, transcription factors, siRNA regulation.
Not a single one can be measured on a sufficiently detailed timescale that it can matter and as a result we are left with trying to guess what are the the relationships between variables.
In addition, this is compound by the lack of explanations about how this relationships might come, despite other indications.

Comparing different datasets is complicated because each is collected with different goals and processed differently.
In addition, there is not a resource were datasets of publications are collected or the relationships between different datasets is not shared.
Authors upload their data to different, not centralized, data repositories, such as, gene expression omnibus ([GEO](https://www.ncbi.nlm.nih.gov/geo/)), European Genome-Phenome Archive ([EGA](https://ega-archive.org/)), European Nucleotide Archive ([ENA](https://www.ebi.ac.uk/ena/browser/home)), among others.
Authors might provide the processed data as supplementary material on their articles.
Some projects whose primary purpose is providing data for the community establishing their own dedicated sites to store the data [@humanmicrobiomeprojectconsortium2012].

Finding different datasets for very similarly purposes is very difficult.
And once it is found there might be batch effects.
There are tools to overcome this, but currently only work if they share some features in common [@ugidos2020].
This usually means having undergone similar RNA sequencing procedures.

All this made finding annotated, appropriate and similar datasets difficult.
We looked up for the most similar datasets in order to be able to confirm our results outside our own cohorts.
On this thesis there were two datasets collected and sequenced: the HSCT and the BARCELONA dataset.

As explained on [methods](#methods-hsct), the HSCT dataset is a very special cohort of patients undergoing hematopoietic stem cell transplant.
This treatment is reserved to patients whose all the other treatment failed and this is the only way to reach remission.
This is common on patients with long time CD.
These patients are highly characterized and there is follow up data for several years.
However, it does not include UC patients and they are not representative of the IBD, or even CD, patients.\
On the HSCT dataset microbiome features were OTUs.
OTUs can not be imputed afterwards to ASV.
As such, the annotation of the 16S data is not the same as in the others datasets.

The BARCELONA dataset includes samples from CD and UC of an ongoing study.
Similar to the HSCT dataset, patients on this study were followed up for up to a year.
The patients were younger and had less years with the disease, which could provide with more insights on the initial relationships between the microbiome and the mucosa of the IBD.

However, the data quality of BARCELONA was not good enough to make reliable analysis and confidently extract hypothesis or relationships.
It is not clear what happened and as a consequence it is not clear how to avoid such problems on the future.
It could be a problem of the original DNA extraction and/or of its sequencing process which did not include both positive and negative controls.

What happened with the BARCELONA dataset -and the organoids cohort not described here- highlights the importance of data quality checks.
On the BARCELONA cohort despite no batch effect or other quality issues with the data as checked with `experDesign`, the diversity indices made impossible using it.
The organoids cohort is a dataset that was sequenced following the `experDesign` recommendations for distribution of samples on different batches.
However, a batch effect was found.
The batch effect was created on the lab process before the samples' sequencing.
Caution and a good relationship with the data sample and data generator is important to discover these kind of problems and ensure the quality of the data.

Other datasets used from published sourced were assumed they had already passed enough controls and had a good quality.
Nevertheless, they were screened to avoid quality issues.

The Puget's dataset dataset provided a good benchmark to test the methods and understand how RGCCA works.
It is a completely different type of data (except for the microarray that is similar to the RNAseq).
But we were not as much interested on the biology as on learning about the methods and possibilities of integration.

Häsler data were obtained using the same sequencing techniques from endoscopic biopsies as our dataset HSCT and Barcelona and it is of the same disease/field.
The 16S data was very similar to the The confirmation that the inteRmodel approach works on it it helped to continue forward.

The taxonomy of the different datasets was done differently.
After the first two datasets it was used the SILVA database to annotate the ASV.

Morgan's dataset is related to IBD but it is from a cohort of patients that underwent colectomy and samples are specific of the pouch or pre-pouch ileum, there are no healthy samples and there is no follow up.
It made very unlikely that a classification of the location could be achieved and the classification of the samples according to the microbiota could not be based on the disease (as all of them had undergone the same procedure with the same disease).
There seems to be gradation on the models on \@ref(fig:morgan-models) that could partially be explained by different degrees of inflammation.

Howell's dataset is very similar to our BARCELONA dataset but on pediatric cases.
It includes both CD and UC (and controls).
The time with the disease of these patients is much lower, and they have might followed less treatments and probably have not had any surgery

The Cristian's dataset was also imputed with SILVA but using a different database version.

### The methods

As seen on the introduction there are many methods are available.
There are frequent releases of new tools and methods.
The most up to date list of tools might be added to a [collaborative list](https://github.com/mikelove/awesome-multi-omics "Awesome multi-omics list").
Between them methods are very different in how they can be used and how they can be classified.
The quality of the software and methods also differs.
Some of them were tested several datasets but their most important validation process undergone is the mathematical validation they have.

With the increase of tools there have been increasingly important to compare different tools.
There are reviews of different tools on the same datasets [@cantini2020], some are more theoretical [@bersanelli2016], others are focused on a different field [@cavill2016].

Of all these methods very few have been applied on IBD datasets.
Recently there has been an article focused on integration on IBD [@sudhakar2022].
On this publication the authors suggest that one must be mindful of the gap between the experimental conditions and the real world.
It also encourages to collect more data about the exposome (the stimuli patients have).
It ends up advising to set up guidelines for multi-omic studies tailored to the field, coordinate in a global framework to prevent redundant studies and ensure efficient funding and resources and disseminate training and education on computational approaches to analyze multi-omic datasets.

Current methodological approaches focus on comparing tools on (several) previously published datasets [@cantini2021], an approach that we have taken too.
This approach was not used to compare different tools, that we also do it, but to validate findings of one dataset in other datasets.
This is specially important due to the lack of golden datasets or a way to reliable simulate datasets as discussed on the previous section \@ref(discussion-datasets).

On IBD, many studies focus on finding some genes or bacteria to answer a narrow question they have in mind, like which bacteria is related to inflammation [@tang2017].
On this thesis, the focus was on finding a good representation of the relationships that allowed to identify genes and bacteria are relevant on the disease.
We made the assumptions that the microbiome presence and the transcriptome are related.
This assumption is backed up by several other previous studies supporting this relationship or others [@holmes2012; @stappenbeck2002; @brand2021; @cornish2008; @thomas1998].

Tools that relate the variance of a block with other variables, both numeric and categoric, are needed to search which variables are important.\
PERMANOVA and `globaltest` worked well to identify which variables about the samples were important.
But they do not give any insight into which specific microbial species are driving the association between the microbiome and the variables [@susin2020].\
In addition, we could miss some other important variables.
It is known the role of other factors outside the omics data collected, mainly from environment factors, genetic susceptibility and immune response [@sartor2006].
Sudhakar *et. al.* [@sudhakar2022] recommend being conscious of the gap between the data available and the biological process.
However, even if we missed them, we probably have not collected it or it is not available, there is nothing at this point that can be done.
This also enters in conflict with a principle of data protection: collect the minimum sufficient information needed.
We might not identify a relevant variable but to identify it we would need to collect too much information from the patients and for little or no clear benefits.\
One variable we did not keep track was the microbiome load which is linked to the gut's microbiome community variation [@vandeputte2017].
We did not measure it because at the time of extraction we didn't quantify the cells present and after the DNA extraction it was too late.

We tried to find which genes and bacteria are correlated between them using `WGCNA`.
It is a tool designed to find common co-occurring patterns based on correlations.
It requires homogeneous samples, with a minimum of 12 samples for condition.
When applied to the whole dataset there might bee too much variance in order of WGCNA to find the proper signal.
This might be the reason why it failed to achieve a good fit on the scale free topology with around 100 of mean connectivity.
In addition, having microbiome and RNASeq on the same matrix, would probably be hard for the process to find good relationships if we applied the same normalization process to both of them without escalation.\
We could have tried to make smaller groups and then compare the modules between them but it groups would be too small because samples were from multiple segments and conditions.

We briefly considered using `STATegRa` but it is not possible to select which interactions between the blocks exists and by that time we already knew it was important to consider several of the variables collected from the patients.
The method implemented on `STATegRA` might be useful for cases where there is a great agreement between blocks or were the variables of the samples are not so important as with our data.

To identify related variables other methods use correlations between the variables [@vila-casadesús2016].
On our dataset we explored the correlations for all the datasets, but the significant correlations were usually driven by an outlier, or was not a good fit of the data due to missing microbiome presence (data not shown).
We tried filtering correlations from those identified by the models, being less restrictive on the significance of the correlation, removing those samples that did not have microbiome presence on at least 5 samples, and remove those samples without that microbiome presence.
All of these variations didn't provide a clear insight over which genes were correlated to which microbiomes, this differs to other publications that relied on them to draw their conclusions [@häsler2017].
This might be due to them relying purely on the Spearman $\rho$ metric instead of visualizing the correlation it measures.

`BaseSet` did not work for its intended usage on this thesis.
It failed because it is computationally expensive to calculate the likelihood of 1500 variables; there are too many combinations.
In addition, the numeric precision of said calculations suffers from the floating point problem and must be considered carefully [@goldberg1991].
To support multiplying more than 1000 float numbers a different strategy such as using log values might be better.
We could not come up with a better strategy to find all the combinations needed, perhaps a better method exists that could be used to find which are the terms more influential to the end result.\
During the peer-review process of the package for its acceptance on rOpenSci, some concerns were raised about conflating probabilities with fuzzy-sets.
For all these reasons this approach was no longer pursued.
However, the package was mentioned as [top 40 packages](https://rviews.rstudio.com/2020/12/22/november-top-40-new-cran-packages/) added on CRAN that month and it might be useful on other circumstances or when less variables are needed.

The development of the `experDesign` package helped avoid batch effects on the sequencing step.
However, as seen on the previous section, this does not prevent all problems with batch effects and still batch effects resulting on a less useful experiment might get through.
As discussed on the related publication, there are several tools already focused on this problem: `OSAT` ([@yan2012]), `anticlust` ([@papenberg2020]) and `Omixer` ([@sinke2021]).
But these tools have some shortcomings, that are covered by `experDesign`: `OSAT` cannot handle missing values and does not work well for arbitrary batches, `anticlust` only accepts numerical variables but it is based on a powerful mathematical theorem and `Omixer` has bugs that prevent comparing with the other tools with no possible workaround.\
In addition, `experDesign` received [requests](https://github.com/llrs/experDesign/issues/22#issuecomment-1033508578) to have a new feature for expanding experiments.
This might help improve the quality of bigger datasets to ensure they can be extended in several sequencing runs.
This feature would be useful for multi-omics datasets or in big cohorts to minimize batch effects usually associated with long running collection of samples.

We selected `MCIA` as a baseline to compare our method because it works well, has a good documentation as well and it is fairly widespread used.
The method was developed after `RGCCA` and recently there have been publications that show that it outperforms other methods on its versatility on different contexts [@cantini2021].
On the dataset analyzed we found it was very competitive with `inteRmodel` but this will be discussed on section \@ref(evaluating-models).

## Designing models

Previous publications using `RGCCA` on IBD focused on validating inflammation markers genes DUOX2 and APOA1 as inflammation predictors ([@tang2017]) from previously published articles [@haberman2014].
Some publication tried to summarize the existing relationships on IBD [@hasler_uncoupling_2016], but none were focused on finding the existing relationships on IBD using `RGCCA` as we did.

Knowing that there are many variables outside transcriptomics and microbiome that are relevant to the disease (and healthy) homeostasis these variables should be included on the models.
In addition, the relationships between the blocks are unknown on both the strength and interaction.
To identify them the connections between blocks had to be modified on `RGCCA` to model the relationships.
Last, what belongs to a block should be carefully considered as the assumption is that the whole block is correlated with the other blocks they are connected.

If one has preexisting theories about the data, a specific model can be used stating these known or hypothetical relationships.
However, if new relationships are being explored or no prior beliefs on the data are held the models should be created with random links between blocks, and evaluate which model is better.

The connections tested required that all models should be connected and no isolated blocks were left, all blocks should be indirectly connected to other blocks.
This avoids optimizing two different networks of blocks that are not connected between them.
Thus, forcing the model to represent all the information.

Typically blocks are defined by each omic data origin and no other information is included.
However, we knew that the transcriptome is mainly related to the location of the samples and we expected that the microbiome would be more related to the variables related to the patients demographic characteristics and dietary and personal habits.
This is specially important because in our datasets we have samples from the same patient and time from multiple locations.
On other studies there are less samples per individual and timepoint (if there are several timepoints) [@howell2018; @hasler_uncoupling_2016; @morgan2015].

Variables of samples were separated according to what they are about on models of family 2.
If it is about the individual it would be on the Demographic block, if it is about time on a Time block, and if about the location of the sample on a Location block (c.f. with tables on design of Puget's \@ref(tab:puget-model2-2), \@ref(tab:puget-model2); HSCT \@ref(tab:hsct-model2) \@ref(tab:hsct-model2-2), \@ref(tab:hsct-model2-3); Häsler: \@ref(tab:hasler-model-2-1), \@ref(tab:hasler-model-2-2), Morgan's \@ref(tab:morgan-model2), \@ref(tab:morgan-model2-2), Howell's \@ref(tab:howell-model2-2) models).

## Evaluating models

To evaluate a model `RGCCA` provides the average variance explained (AVE), inner and outer (see section \@ref(rgcca-output)).
As we are more interested on the model of the relationships the inner AVE makes more sense to evaluate it.

Furthermore, to evaluate a design bootstraping can be used to know how well the design does apply to a variety of data.
Although on `inteRmodel` there is the option to use a leave-one-out procedure, we didn't use it to evaluate the fitness of the models.

Using an external cohort to validate the same model, or using a different method to see if it finds the same relationships or explains the data as accurately is also a common approach to evaluate and validate models.
Using the same approach on different data helps to ensure the replicability of the results [@community2021].

```{r reproducible-matrix, fig.scap="Reproducibility matrix", fig.cap="Reproducibility matrix indicating the terminology used between using the same method and the same data. Figure from The Turing Way: A Handbook for Reproducible Data Science (Version v1.0.1)."}
include_graphics("images/turing_way_reproducible-matrix.jpg")
```

We used the same approach on 4 different cohorts, from different origins and with different types of samples, but all are related to IBD, have 16S data and intestinal transcriptome.
Some of them have multiple samples from the same individuals while others do not [@hasler_uncoupling_2016].

We also compared our method with a different one to see how generalisable are the results.
Of the multiple methods available we used [`MCIA`](https://bioconductor.org/packages/omicade4 "Omicade4 package") [@mengMultivariateApproachIntegration2014].
We compared it with `inteRmodel` by looking at the area under the curve for classifying the samples with the canonical component of the transcriptome data according to their location.

The procedure of separating independent variables in their own block of data and later search the best model that fits the data provides a good strategy that should be consider for integration efforts.
The procedural method of searching a model and testing them is implemented on [`inteRmodel`](https://llrs.github.io/inteRmodel/ "inteRmodel").
But the most important thing is to consider which variables are independent of which and if they can be separated into a block for later usage on the modeling (See [@pearl2011]).
This can lead to undesired conclusions like the effect known as [Simpson's paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox) [@simpson1951].

Splitting the variables of each sample into several blocks forces `RGCCA` to adjust for a new canonical dimension.
The omics block such as gene expression and 16S data could be split, as the expression of some genes influence other genes, such as [transcriptor factors](https://en.wikipedia.org/wiki/Transcription_factor) (First mentioned on [@stillman1984]) , [miRNA](https://en.wikipedia.org/wiki/MicroRNA) [@lee1993], [siRNA](https://en.wikipedia.org/wiki/Small_interfering_RNA) [@hamilton1999]... All these interactions and regulations could distord the canonical correlations.
However, the nature of this relationships is not linear and the interaction between them is multiple and very complex.
Its complexity has prevented to accurately account for all subcellular reactions at speeds that could be useful (it has only been recently accomplished for a prokaryote cell [@thornburg2022]).
In addition, these interactions are time dependent, not linear and are highly interconected between a large number of variables.
For these reasons gene expression and 16S block were not split into several blocks.

Besides comparing the results of different methods, these models need to be evaluated by the insights they provide on the biological system they are being applied to, in our case IBD.
So far the models were only discussed on their technical merits.

It is known that mucosal transciptome is related to localization of the samples [@criss2021].
The difference is so great that many times the colon and ileum samples are analyzed separately.
As such, it was a reasonable assumption to expect models to reflect this differences on the gene expression canonical component.

The variability of microbiome challenges finding clear patterns.
On healthy humans, it has been suggested that there is a common microbial composition on all humans [@arumugam2011]. Such theory suggests three groups of similar microbiota composition, named enterotypes. However, the enterotypes classification is not unanimously accepted [@koren2013; @cheng2019].

There are many factors that influence the gut microbiome [@hasan2019]. But the role of microbiome on IBD has recently gained some interest [@khanna2014; @bringiotti2014; @lloyd-price2019].
It has been associated with predictors of CD treatment response and suggested that they could be useful for building an improved classifier for CD and treatment response based on sufferers' microbiome in the future [@douglas2018].
Thee is for instance, an association between IBD and butyrate producers (See [@takahashi2016]) which has shown to influence permeability of the epithelial barrier [@ferrer-picón2020].

The relapse nature of IBD, suggests that at different time points the gene expression or the microbiome might be different.
For this reason, time is an important variable when modelling the disease.
Even microbiome of patients in remission have different microbiome from non-IBD patients [@halfvarson2017].
If multiple timepoints are taken they should be taken into account to identify the state of the disease for each patient.
On the cohorts analyzed on this thesis, only the HSCT and the Häsler dataset had

As well as they multiple samples with microbiota from the same patient provide a common microbiome background, which can help to identify altered microbiome states later on.
Due to technical challenges very few datasets provide data from the same patient on multiple locations.

[@jiang2019] A paper about multi-omics and microbiome...

[@krassowski2020] advice and recommendations on software engineering and reproducibility practices to share a comprehensive awareness with new researchers in multi-omics for end-to-end workflow.

## Relevance for other research

It is hard to provide more information that can be later used by researchers on the wet lab.

Paper about using transcriptomics to infer inflammation without colonoscopy [@ungar2022]

There is a disconnect between the computational side and the experimental side, driven by the difficulty to think an experiment to test the new information that multi-omic experiments provide.

Many combinations possible that are hard to explore, further research on how to reduce the space of possible combinations of bacteria or evaluate which combinations are more important might be useful on the future.
As this might help focus on the most promising bacteria.

## Implications of research

Translational research?
How to apply this results ?

Sequence just the ASV on patients to classify them on disease might be an option that would require further clinical validation.

Selecting which genes are related to the microorganisms is will require also further validation (for which I did not have the creativity to think of).

The several environmental factors highly affect the disease, so analysis or comparisons without taking into account them might provide misleading or false results.

Multi-omics seems to focus on metagenomics, metatranscriptomics and metaproteomics and abandon plain 16S sequencing [@zhang2019].

<!--# From @collij2021 add references/adapt-->

To study complex systems, new technologies like "organ-on-chip" or more specifically "gut-on-chip" are being developed [@collij2021].
By introducing gut microbiota, these system will be of great help in the stud of the interaction of the gut microbiota dn the intestinal epithelium.
