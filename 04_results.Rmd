# Results

## Packages

### experDesign

`experDesign` package built in R was released for the first time on CRAN on 2020-09-08 after nearly a year after the initial release made on [github](https://github.com/llrs/experDesign).

The package uses functional programming to create and modify objects and the features used.
The package didn't need a new class created to work and bases its performance on the large body of work made by the R core team.
It simply adds the needed information on the columns of the introduced `data.frame` or returns an appropriate vector.

`experDesign` functions are divided into several categories:

-   Helper functions to aid on deciding how many batches are or how many samples per batch.
    There are some also that report how good a given distribution of the samples felt for a given dataset.

-   Functions generating indexes.

-   Functions distributing the samples on indexes

Regarding time related variables `experDesign` will use them as factors, while issuing a warning to the user.

Since its development it has been used on a couple of batch designs, one for organoids bulk RNA-seq and another one for biopsies bulk RNA-seq from the BARCELONA cohort.

On both cases it worked well and no batch effect were created when sequencing samples.
However on the organoids dataset, the change on the method of producing them introduced a batch effect that made it impposible to compare samples before and after that change.

```{r experDesign, include=FALSE}
library("dlstats")
library("dplyr")
cran_stats("experDesign") %>% 
  group_by(month = format(end, "%Y/%m")) %>% 
  summarise(d = sum(downloads)) %>% 
  ungroup() %>% 
  pull(d) %>% 
  median()
```

Since its release on CRAN it has had a median of \~400 downloads each month from RStudio package manager, so the total number of downloads is higher as not all the installations are from RStudio's mirror.

### BaseSet

`BaseSet` package, built in R, was released for the first time on CRAN on 2020-11-11 after nearly two years after the initial work started on [github](https://github.com/llrs/BaseSet).

The package uses both functional programming and object oriented program to create and modify the TidySet S4 object defined[^results-1].
Mixing it with S3 generic functions it provides a powerful interface compatible with the tidyverse principles, a [group of packages](https://www.tidyverse.org/) following the same design.
The package provides a new class to handle fuzzy sets and the associate information.

[^results-1]: S4 is one of the object programming paradigms on R.
    For a more complete overview and differences see [Advanced R](https://adv-r.hadley.nz/oo.html "2nd edition") [@wickham2019].

`BaseSet` methods are divided into several categories:

-   [General functions](https://docs.ropensci.org/BaseSet/reference/index.html#general) to create sets of the TidySet class or convert from it to a list or about the package.

-   [Set operations](https://docs.ropensci.org/BaseSet/reference/index.html#set-operations) like adjacency cartesian product, cardinality, complement, incidence, independence, intersection, union, subtract, power set or size.

-   [Functions to work with TidySets](https://docs.ropensci.org/BaseSet/reference/index.html#set-operations) to add relationships, sets, elements or some complimentary data about them.
    Remove the same or simply move around data or calculate the number of elements, relations and sets.

-   [Functions to read](https://docs.ropensci.org/BaseSet/reference/index.html#reading-files) files from formats where sets are usually stored in the bioinformatician world: GAF, GMT and OBO formats

-   Last, some [utility functions](https://docs.ropensci.org/BaseSet/reference/index.html#utiles) to set name conventions, use set_symbols and some other auxiliary functions

The package had a long development process with initial iterations basing on GSEABase package which was later abandoned to include also some uncertainty on the relationship of a gene with a given gene set.

The package also participated on an exploration on part of the Bioconductor community (project to develop, support, and disseminate free open source software that facilitates rigorous and reproducible analysis of data from current and emerging biological assay) for more modern and faster handling of sets.
There were three different packages created as part of this process, `BaseSet`, `BiocSet` published [on Bioconductor](https://bioconductor.org/packages/BiocSet/) and `unisets`, available [on github](https://github.com/kevinrue/unisets).
The different approaches were presented at a birds of feather on BioC2019.

The package passed the review on the rOpenSci organization ([See review](https://github.com/ropensci/software-review/issues/359 "Review on Github")) and now is part of the packages hosted there too.

```{r BaseSet, include=FALSE}
library("dlstats")
library("dplyr")
cran_stats("BaseSet") %>%  
  group_by(month = format(end, "%Y/%m")) %>% 
  summarise(d = sum(downloads)) %>% 
  ungroup() %>% 
  pull(d) %>% 
  median()
```

Since its release on CRAN it has had a median of \~400 downloads each month from RStudio package manager, so the total number of downloads is higher.

### inteRmodels

The package was build once the method used to find accurate models of the relationships of the data available of a dataset using RGCCA was established.
It simplifies the process and makes it easier to perform it.

The package consists of functions that can be grouped in three categories:

-   To look for models and evaluate them.
    There are functions to search for a model given some rules, that check them using leave-one-out methodology.

-   Reporting: To make better reports by improving handling of names or simplifying the objects or how to calculate scores.

-   Building: To easier build correct models on RGCCA, simplifying the process to create a symmetric matrix.

Currently it is only available on github, so the number of downloads and usage is unknown but since its release a user has contacted to keep it up to date with development versions of RGCCA.
Which now it is compatible with the next release of [RGCCA being prepared](https://github.com/rgcca-factory/RGCCA/tree/CRAN)[^results-2].
Together with a copy of the RGCCA packages with more tests has enabled to identify changes on the RGCCA package that could affect users.

[^results-2]: I also contributed with some comments and feedback to the package to make it easier to read the source and check the inputs and improve the documentation so that it is coherent with the code and previous results of the functions.

## Analysis

On the following sections the main results of analyzing each dataset are presented.

### Puget's dataset {#results-puget}

On this dataset the different parameters and capabilities of RGCCA were tested.

The three different methods, centroid, factorial or horst were tested and compared.
The main result of this comparison was that the differences of the selection of the variables mattered more than the number of variables selected with each method.
The models were tested with different weights on all three schemes: horst, centroid and factorial.
The horst and the centroid scheme were similar while the factorial resulted in the most different AVE values (see [S1 Data](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0246367#pone.0246367.s001) of [@revilla2021]).
The centroid scheme was selected because it takes into account all the relationship regardless of the canonical correlation sign between the blocks and it is similarity to horst scheme.

The effect of the sparsity value was measured by its effect on the inner AVE scores and the combination of the different values for each block.

![(#fig:tau2AVE) Effect of tau on the inner AVE. The suggested tau value is the column between the regular grid.](images/pugets_tau_to_AVE.png)

Exploratory analysis with the superblock model was done.
The first two components of the suprblock didn't help to explain the biology or classify the tumors:

![(#fig:superblock) First components of the superblock](images/pugets_superblock.png)

The same data was used to look for a good model from the data itself including a model with a superblock but looking at the first component of the CGH and transcriptome block.
This allowed to visually inspect if each model's components helped to classify the samples:

![(#fig:pugets-models) Different models tried with the same data showing the first components of the CGH data and the transcriptome.](images/pugets_models.png)

Showing the components of the CGH and the transcriptomics of the superblock show better classification than that of the superblcok.
However the other models show a better classification of the samples with much simpler models.

<!--# Slightly modified from the article!! -->

To find these models the three blocks with the best tau and the centroid scheme were analyzed by changing the weights between 0 and 1 by 0.1 intervals.
According to the inner AVE, the best model was the one in which the weights (1) between the host transcriptome and location, (2) the host transcriptome and the CGH, and (3) the CGH block were linked to variables related to the location with weights of 1, 0.1 and 0.1, respectively.

When we added a superblock to the data, there was a slight increase of 0.01 on the inner AVE of the model.
The model with the superblock that explained most of the variance was that in which the weights of the interaction within (1) the host transcriptome, (2) between the superblock and the CGH, (3) between the host transcriptome and the localization, and (4) between CGH and the host transcriptome were 1, 1, 1 and 1/3, respectively.
To see if the superblock could classify the sample by location, we plotted the first two components of the superblock.

We can clearly see that they do not classify the samples according to the location of the tumor, which is known to affect the tumor phenotype [@puget2012].

<!--# TODO: Show plot of the superblock result -->

Adding one block containing the age of the patient and the severity of the tumor to the model, decreased the inner AVE.
The best model with these blocks, according to the inner AVE, was that in which the interactions (1) within the host transcriptome, (2) between the host transcriptome and the localization, (3) between the host transcriptome and(4) the CGH and between the CGH and the other variables were 1, 1, 1/3 and 1/3, respectively.
The first components of each model can be seen in the figure:

![(#fig:pugets-models-bis) Different models tried with the same data showing the first components of the CGH data and the transcriptome.](images/pugets_models.png)

We can observe on the figure, the strong dependency between gene expression and location since the first model while the weaker relationship with the CGH assay [@puget2012].
On the other hand, the major difference is the dispersion on the CGH component on each model.

The effect of the superblock and weights on different models to the inner AVE.
There are significant differences between having the superblock and not having it.
![(#fig:pugets-weights) Effect of superblock and weights on the inner AVE](images/pugets-weights.png)

### HSCT dataset {#results-hsct}

The permanova analysis was performed on this dataset to estimate which were the variables that are more relevant.
From the many variables the location, sex, patient id and others were found to be related to the variability of the microbiome or the transcriptome on this dataset.

<!--# From gourmiting 2 2018-03-13 -->

With the permanova analysis we found that 80% and 90% of the variance of normalized RNA-seq data and microbiome data respectively is explained by the variables of location, disease, sex, and the interaction between disease and sex.
On the transcriptome the most important factor is location which is more than 50% of the variance, while on the microbiome data the most important factor is the patient id.

<!-- # Image with the results for a table and to explain main factors of interaction-->

![](images/hsct-adonis.png)

<!--# global test from the comments on TRIM/intestinal_16S_RNAseq_metadb/variance.R -->

With globaltest the results were similar.
The resulting p-value was well below the 0,05 threshold defined for RNA-seq data on the models including the segment of the sample, sex and treatment.
![](images/hsct-globaltest.png) On the microbiome data the results were similar but the p-value was considerably higher but still below the threshold.

<!--# TODO: Include diversity index values -->

![](images/hsct-ASV-diversity.png)

Diversity indices of the samples were explored and compared for several subsets.
Splitting by location of the sample and disease provided the highest differences and the diversity index along time did not change much.

<!--# TODO: explain why WGCNA didn't work out -->

Weighted gene co-expression network analysis did not provide relevant links between bacteria and transcriptome as it failed to find an acceptable scale free degree.

<!--# TODO: explain why STATegRa didn't work out -->

STATegRa didn't show a value of, the assumption that there is a shared common factor without influence of other categorical variables was too much.
In addition, the model is fixed, so it didn't allow to find new or other relationships that are not one to one.

With RGCCA we could select different models and use all the data available without much assumptions.
The models with the highest inner AVE of the family 1 and the family 2 models were similar to those on the Häsler dataset.
The weights of these models can be observed here:

<!--# TODO: Show tables of the models -->

The best model of the family 2 confirmed a relationship between the host transcriptome and the location-related variables, while the microbiome was associated with the demographic and location-related variables (see Figure and [S2](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0246367#pone.0246367.s002) data of [@revilla2021]).
Overall, we see that the relationships in the model affected the distribution of samples on the components of both the host transcriptome and the microbiome.

<!--# TODO Add figure about the components on our own dataset -->

The different models selected different variables, some of which are shared between models.
The most similar models are those that have split the metadata into 3 blocks, followed by those that have the metadata in a single block.

In order to analyze the accuracy of the models, one thousand bootstraps were used to integrate the data from the HSCT CD dataset.
Each bootstrap had its own dispersion on the variables according to the samples selected, the distribution of the bootstraps used are represented here:

![Dispersion of the bootstraps on the age and percentage of colon and controls samples.](images/hsct-bootstrap-characteristics.png)

Evaluating the same model on each bootstrap lead to a dispersion on the inner AVE of the model.
The lower the dispersion, the more robust the model was to different conditions than in the initial testing.

![The point with the black circle is the AVE of the original data. The dispresion is shown by the elipses](images/hsct-bootstrap.png)

With the bootstrapped models we used BaseSet to estimate the probability that each variable to be relevant for the association with a disease.
However, due to big amount of small probabilities when using the BaseSet package to calculcate which variables are more relevant it couldn't provide a good estimation on time.

MCIA was applied as a baseline of the integration, the first two components were represented similarly to those of the blocks when using RGCCA.

<!--# TODO: Include plot with the result -->

![MCIA first two syntetic variables on the IBD related cohorts.](images/paper1_MCIA.png)

The AUC of classifying the transcriptome in colon or ileum segments was compared between the two methods.

<!--# TODO: Add plot of the comparison of AUC -->

![ROC curve of the different datasets with the models from RGCCA and the result with MCIA](images/paper1_MCIA.png)

The different models selected different variables as can be seen below:

![(#fig:hsct-features) Upset plot of the variables selected on each model showing the intersection between the different models](images/hsct-features.png)

### Häsler's dataset {#results-hasler}

In this dataset, the parameter tau behaved slightly differently than with the previous dataset but the value from the Schäfer's method for tau was close to the best value.

<!--# TODO: Show how different/what happened with tau -->

In contrast to the puget's dataset, the model with the highest inner AVE was model 1.2 .
Model 2.2 has a relationship of 0.1 between microbiome and the host transcriptome and of 1 between the location and the host transcriptome.
The microbiome block is also related by a factor of 0.1 with the demographic block and of 1 with the time block.
Lastly, the time and the demographic block are related by a factor of a 0.1.
In either case the family 1 and family 2 models can correctly separate by sample location (colon or ileum) but not by disease type or inflammation status.

<!--# TODO: add figure 2 of the article -->

![(#fig:hasler-models) Models on the Häsler's dataset](images/hasler-models.png)

The model 2.2 clearly separated ileum and sigma segments on the transcriptome component as expected.
Not a single models separates the different type of samples, and there is no observable cluster of IBD samples and the other samples.

MCIA was applied as a baseline of the integration.

![ROC curve of the different datasets with the models from RGCCA and the result with MCIA](images/paper1_MCIA.png){alt="ROC curve of the different datasets with the models from RGCCA and the result with MCIA"}

The AUC of classifying the transcriptome in colon or ileum segments was compared between the two methods.

### Morgan's dataset {#results-morgan}

We tested if results of inteRmodel were consistent on this dataset.

<!--# TODO: RGCCA plots of models -->

<!--# TODO: Table of models -->

![(#fig:morgans-models) First component of the transcriptone and microbiome of the Morgan's dataset.](images/morgans_models.png)

<!--# TODO: MCIA plot-->

![(#fig:morgans-bootstrap) Inner and outer AVE scores of the bootstrapped models.](images/morgans_bootstrap.png)

<!--# TODO: AUC comparison of RGCCA and MCIA -->

### BARCELONA dataset {#results-barcelona}

This dataset was processed but the results are not trustable as the microbiome diversity falls off the accepted values.

Diversity plots

<!--# TODO: Add plots of diversity -->

### Howell's dataset {#results-howell}

This dataset was processed to confirm the results on the previous datasets.

Model 1.2 was the best according to the AVE score but perform worse when attempting to recreate known biological differences via classifying samples.
Model 2.2 was selected.

<!--# TODO: show models -->

<!--# TODO: show bootstraps -->

<!--# TODO: show MCIA plots -->

### Hernández' dataset {#results-hernandez}

This dataset was processed to confirm the results on the previous datasets.
